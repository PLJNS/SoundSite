---
layout: page
title: Notes
subtitle: From Paul Jones at Rutgers University
---
{% raw %}
<h1>
Design and Analysis of Computer Algorithms <small>with Professor Kostas Bekris</small>
</h1>

<h2>
Syllabus
</h2>

<h3>
Topics
</h3>

<p>
We will cover a large subset of the following and possibly some new algorithmic topics and applications, as time permits:
</p>

<ul>
<li><p>
Mathematical tools. Review of mathematical background, concepts of algorithm design, complexity, asymptotics, induction, and randomization. Fibonacci numbers. Euclidean gcd algorithms. Universal hashing.
</p></li>
<li><p>
Divide and conquer. Fast integer multiplication; recurrences; the master theorem; mergesort; randomized median and selection algorithms; quicksort; fast matrix multiplication.
</p></li>
<li><p>
Sorting. Lower bounds for comparison-based sorting; binsort and radix sort.
</p></li>
<li><p>
Dynamic programming; Paradigm of SPs in DAGs; longest increasing subsequence; approximate string matching; integer and (0,1) knapsack problems; chain matrix multiplication; single-pair reliable SPs, all-pairs SPs; independent sets.
</p></li>
<li><p>
Graph search. Graph classes and representations; depth first search in undirected and directed graphs; topological search; strongly connected components. Breadth first search and layered DAGs.
</p></li>
<li><p>
Shortest Paths (SPs) in digraphs. Single-source SPs for nonnegative edge weights; priority queues and Dijkstra; SPs in DAGs; single-source SPs for general edge weights. Maximum adjacency search.
</p></li>
<li><p>
Greedy algorithms. Spanning trees and cuts, analysis of union-find and path compression; MST algorithms; randomized algorithm for global minimum cuts; approximate set cover.
</p></li>
<li><p>
Network flows. Max flow min cut theorem and integrality; fast algorithms; disjoint (s,t)-dipaths; maximum bipartite matching &amp; minimum vertex cover. Global minimum cuts.
</p></li>
<li><p>
Elements of NP-completeness &amp; problem reductions.
</p></li>
<li>
NP-hard problems. Search and selected approximation algorithms.
</li>
</ul>

<h3>
Prerequisites
</h3>

<p>
Courses:
</p>

<ul>
<li>
CS 112 Data Structures
</li>
<li>
CS 206 Introduction to Discrete Structures II
</li>
</ul>

<p>
We assume (and briefly review early on in the class) elements of discrete mathematics, such as logarithms, proofs by induction, series and sums, permutations, asymptotics (big-Oh, big-Omega notation), basics of solving recurrences, as well as concepts of programming and data structures, e.g., linked lists, stacks, queues, trees, binary search, recursion, hashing, priority queues, graph algorithms, sorting.
</p>

<h3>
Reading Material
</h3>

<p>
The class will primarily draw upon material from the following book:
</p>

<ul>
<li>
&quot;Algorithms&quot; by Dasgupta, Papadimitriou &amp; Vazirani, McGraw Hill, 2008.
</li>
</ul>

<p>
The following book may also be used as reference:
</p>

<ul>
<li>
&quot;Introduction to Algorithms&quot; by Cormen, Leiserson, Rivest &amp; Stein, McGraw Hill (The chapters in the calendar below refer to the 2nd edition)
</li>
</ul>

<p>
The books are not required for the class. Students are expected to take notes during the presentation of the material in the classroom and the recitations. Homeworks and exams will be based on the presented material.
</p>

<h3>
Exams
</h3>

<p>
There will be three exams: two midterms and one final. The first midterm will cover the material of the first third of the course, and the second midterm will cover the second third of the course. The final exam will cover material from the entire class. Check the tentative schedule for updates. All exams will be in-class on a date arranged and announced ahead of time.
</p>

<p>
A missed exam draws zero credit. Emergencies will be considered upon submitting a University-issued written verification to the Instructor; for assistance contact your Dean's Office. Also, check the definition of <a href="http://sasundergrad.rutgers.edu/forms/final-exam-conflict">Final Exam</a> by SAS.
</p>

<h3>
Homework Assignments
</h3>

<p>
There will be 4 to 5 homeworks. You will be informed in advance when an assignment is due. A tentative scheduled is available on the course's website. The homeworks consist of practice questions which are intended to assist students in mastering the course content. They may also potentially involve limited programming effort.
</p>

<p>
Homeworks should be completed by teams of students - three at most. No additional credit will be given for students that complete a homework individually. Please inform Athanasios Krontiris about the members of your team (email: tdk.krontir/AT/gmail.com).
</p>

<p>
Students will receive 10% extra credit if they typeset their report using LaTeX or 5\% extra credit if they typewrite their answers (e.g., using Word). Submit only PDF documents. For instance, if a pair was to receive a score of 62/100 and they typeset their report, then their score will be 68/100, i.e,. they receive a bonus of +10\% of 62 points. Resources on how to use LaTeX are available below.
</p>

<h3>
Submission Rules
</h3>

<p>
No late submission is allowed. If you don't submit a homework on time, you get 0 points for that homework. The deadline will typically correspond to the beginning of a lecture. Students can submit their homeworks electronically via Sakai.
</p>

<h3>
Grading System
</h3>

<p>
The final grade will be computed according to the following rule **(this is tentative and can change)**:
</p>

<p>
final grade = max(Case A: With Homeworks, Case B: Without Homeworks)
</p>

<p>
Case A: With Homeworks
</p>

<ul>
<li>
Homeworks: 20 points total
</li>
<li>
First midterm: 25 points
</li>
<li>
Second midterm: 25 points
</li>
<li>
Final exam: 30 points
</li>
<li>
Participation: +/- 5 points (this is up to the discretion of the instructor and the TAs)
</li>
</ul>

<p>
Case B: Without Homeworks
</p>

<ul>
<li>
First midterm: 30 points
</li>
<li>
Second midterm: 30 points
</li>
<li>
Final exam: 40 points
</li>
<li>
Participation: +/- 5 points (this is up to the discretion of the instructor and the TAs)
</li>
</ul>

<p>
On any assignment (homework or exam), you can either attempt to answer the question, in which case you will receive between 0 and 100% credit for that question, or you can write &quot;I don't know&quot;, in which case you receive 25% credit for that question. Leaving the question blank is the same as writing &quot;I don't know.&quot; You can and will get less than 25% credit for a question that you answer erroneously.
</p>

<p>
Finally, the first exam is a make-or-break situation. If your score on the first exam is 26% or less (which amounts to a blank exam) then you fail the class. The first exam will be early enough for you to drop the class.
</p>

<p>
Your participation grade can be positive or negative. By default your participation grade is 0..., e.g., if you typically come to the lectures/recitations but you rarely answer questions during the lectures or the recitations, your participation grade will be 0. Positive participation grades will be given to students that actively participate in lectures and recitations. You can also receive a negative participation grade depending on the level of your involvement in the course lectures and recitations (or lack there of) or because of issues related to collusion or cheating in homeworks and exams.
</p>

<p>
The mapping of scores to letter grades will be determined at the end of the semester. As a <strong>rough</strong> guide, the following rule may be used for the final grade **(it will be adapted close to the end of the semester)**:
</p>

<ul>
<li>
A: &gt; 89
</li>
<li>
B+: 80-89
</li>
<li>
B: 70-79
</li>
<li>
C+: 60-69
</li>
<li>
C: 50-59
</li>
<li>
D: 40-49
</li>
<li>
F: less than 40
</li>
</ul>

<p>
Students interested in a recommendation letter by the instructor will be offered one only if they achieve a score above 95 after the completion of the course.
</p>

<h3>
Questions about Grading
</h3>

<p>
If you have a question or complaint regarding the points you received on specific parts of a HW assignment, or an exam, staple a sheet of paper on the graded item, stating specifically but very briefly what parts of that document you wish to have reviewed and forward it to Athanasios Krontiris, who will handle the process of communicating with the instructor and the other TAs. Please refrain from verbal arguments about grades with the instructor or with any of the TAs. We will try to get back to you within two weeks. The deadline for submitting such requests is the last lecture.
</p>

<h3>
Academic Standards
</h3>

<p>
Exams are to be treated as individual efforts. Homeworks are not to be treated as collective efforts beyond the participation of the team members! Discussions are not allowed on how to solve specific questions in homeworks. Do not discuss assignments with students that are not currently taking the class.
</p>

<p>
A severe penalty will be given to any assignment which indicates collusion or cheating. The usual penalty for cheating on an assignment or an exam is failure in the course. At a minimum your participation grade will be influenced negatively. Stealing another person's listing or having another person &quot;ghost write&quot; an assignment will be considered cheating.
</p>

<p>
Turning in work without properly citing the sources of the content included in your work is plagiarism. All kinds of sources are included in this definition, even those downloaded from the web, in which case an operable link must be cited. Plagiarism from the web or other sources is considered cheating and has the same effects. Even with a reference, submitting an answer to a homework question, verbatim from any source and without any contribution on your part, draws zero credit.
</p>

<p>
You should carefully study the website of Rutgers University on <a href="http://academicintegrity.rutgers.edu/">Academic Integrity</a> and the corresponding <a href="http://academicintegrity.rutgers.edu/policy-on-academic-integrity">policy</a>, as well as the corresponding <a href="http://www.cs.rutgers.edu/policies/academicintegrity/">policy</a> from the department of Computer Science. Your continued enrollment in this course implies that you have read these policies, and that you subscribe to the principles stated therein.
</p>

<h3>
LaTeX Resources
</h3>

<p>
General info on what you can do with LaTeX: <a href="http://www.maths.tcd.ie/%7Edwilkins/LaTeXPrimer/">Getting Started with</a> <a href="http://www.cse.unr.edu/robotics/bekris/cs482_f09/sites/cse.unr.edu.robotics.bekris.cs482_f09/files/lshort.pdf">The Not So Short Introduction to</a> <a href="http://www.cse.unr.edu/robotics/bekris/cs482_f09/sites/cse.unr.edu.robotics.bekris.cs482_f09/files/comprehensive.pdf">Comprehensive List of Latex</a> <a href="http://www.logicmatters.net/latex-for-logicians/">Latex for Logicians</a>
</p>

<p>
Mac <a href="http://ii2.sourceforge.net/tex-index.html">Tex on Mac OS X</a> <a href="http://www.tug.org/mactex/">MacTex</a>
</p>

<p>
The first link describes many alternatives that are available for installing Tex on a Mac. The second link forwards to the MacTex package, one of the alternatives mentioned in the first website. MaxTex provides everythink that you need to use Latex on Mac except from a text editor. It is, however, compatible with a wide variety of popular editors (e.g., Alpha, BBEdit, Emacs, VIM, iTeXMac, TeXShop). Note that MaxTex is a large package.
</p>

<p>
Carbon Emacs has been succesfully tested with MacTex. After installing MacTex, it is possible to directly compile and view *.tex files from Carbon Emacs's UI.
</p>

<p>
Note for Mac users: You will probably have problems previewing your PDF output when using the postscript images provided by the instructor for developing the notes. Nevertheless, the PDF file can be printed properly. Prepare your document without the images and then add them. You will probably still be able to preview the intermediate .dvi output file with the &quot;xdvi&quot; program.
</p>

<p>
Linux (Ubuntu) <a href="https://help.ubuntu.com/community/LaTeX">Latex on Ubuntu</a> <a href="http://www.tug.org/texlive/">Tex Live</a>
</p>

<p>
You just have to download and install the proper packages described above (e.g., through apt-get), use your favorite editor (e.g., emacs) to prepare a *.tex file and then you compile (run at least two times: &quot;latex filename.tex&quot;) to get the *.dvi output. You can go from dvi to postscript with the command &quot;dvips&quot; and you can convert postscript to pdf with the command &quot;ps2pdf&quot;.
</p>

<p>
Windows <a href="http://faculty.smu.edu/barr/latex/">Latex for Windows help</a> <a href="http://miktex.org/">MikTex (Latex for Windows)</a>
</p>

<p>
If you follow the instructions on the first link you should be able to get it working on a Windows system.
</p>

<p>
Below you can find Windows executables (32 bit) for the following programs (follow the order when installing):
</p>

<p>
<a href="http://www.cse.unr.edu/robotics/bekris/cs482_f09/sites/cse.unr.edu.robotics.bekris.cs482_f09/files/setup-2.7.3092.exe">MiKTeX</a>
</p>

<p>
<a href="http://www.cse.unr.edu/robotics/bekris/cs482_f09/sites/cse.unr.edu.robotics.bekris.cs482_f09/files/gs863w32.exe">Ghostscript</a>
</p>

<p>
<a href="http://www.cse.unr.edu/robotics/bekris/cs482_f09/sites/cse.unr.edu.robotics.bekris.cs482_f09/files/gsv49w32.exe">Ghostview</a>
</p>

<p>
<a href="http://www.cse.unr.edu/robotics/bekris/cs482_f09/sites/cse.unr.edu.robotics.bekris.cs482_f09/files/winedt55.exe">WinEdt</a>
</p>

<h2>
January 24th, 2014 - Lecture
</h2>

<h3>
Fibonacci
</h3>

<ul>
<li><p>
He was an Italian mathematician in the 13th century who designed a famous sequence of numbers.
</p>

<p>
<span class="math">\[ 0, 1, 2, 3, 5, 8, 13, ... \]</span>
</p>

<ul>
<li><p>
We can design an algorithm to compute this.
</p>

<p>
<span class="math">\[F_n = F_{n - 1} + F_{n - 2} \]</span>
</p></li>
<li><p>
And this can be expressed as a psuedocode function
</p>

<pre><code>fib(n) {
    if (n == 0 | n == 1) {
        return n;
    } else {
        return fib(n - 1) + fib(n - 2)
    }
}
</code></pre></li>
<li><p>
<span class="math">\(T(n)\)</span> grows at least as much as the value of <span class="math">\(Fn\)</span>.
</p>

<p>
<span class="math">\[ F_n \approx 2^{0.694n} \]</span>
</p>

<ul>
<li>
This grows exponetially as a function of n.
</li>
</ul></li>
</ul></li>
<li><p>
If today, you can compute the 100th number, then after a year, hardware will allow you to computer the 101th number in a sequence.
</p></li>
<li><p>
A new function for Fibonacci:
</p>

<pre><code>fib(n) {
    if (n &lt;= 1) {
        return n;
    }

    int F[n];
    F[0] = 0;
    F[1] = 1;

    for (int i = 2; ; n++) {
        F[i] = F[i - 1] + F[1 - 2];

        return F[n];
    }
}
</code></pre></li>
<li><p>
Eventually, the cost is not exponetial, as now our function is linear, it's in the order of n.
</p></li>
<li><p>
Now, it's quite feasible to get to 200,000th number in the sequence.
</p></li>
</ul>

<h3>
Computations
</h3>

<ul>
<li><p>
So far, all computations were treated as equal cost operations.
</p>

<ul>
<li>
This is a convinient simplication, but it is not true.
</li>
<li><p>
For instance, addition.
</p>

<ul>
<li><p>
For numbers that can fit within your computer's register, say, 32-bits or 64-bits, then it takes only steps.
</p></li>
<li><p>
But for big numbers like the Fibonacci numbers, like <span class="math">\(0.69 / n\)</span> bits.
</p></li>
</ul></li>
</ul></li>
<li><p>
Arithemetic operations on large numbers cannot be treated as a single step. You need to think about their representation.
</p>

<ul>
<li>
<p>We need to think in terms of the representation of numbers.</p>
<ul>
<li>
For example, a number <em>N</em> in base <em>b</em>.
</li>
<li>
You need <span class="math">\(\lceil{log_b (N+1) \rceil\)</span> digits.
</li>
</ul></li>
</ul></li>
<li><p>
If cost of addition is linear to the size of bit representation, what is the cost of <code>fib(n)</code>?
</p></li>
</ul>

<h3>
Running Time Simplification
</h3>

<ul>
<li><p>
If you have two functions that represent two running times for algorithms,
</p>

<p>
<span class="math">\[f(n) = O(g(n))\]</span>
</p>

<p>
<span class="math">\[\exists c, n_0, f(n) \le c \times g(n) \forall n \ge n_0\]</span>
</p></li>
</ul>

<h2>
January 29th, 2013 <small>Lecture</small>
</h2>

<h3>
Multiplication
</h3>

<ul>
<li><p>
Example: 13 times 11
</p>

<pre><code>    1101
    1011
    ----
    1101
   1101
  0000
 1101
 10001111
</code></pre></li>
<li><p>
To compute each row, eitther &quot;X&quot; or &quot;0&quot;, left-shifted.
</p>

<ul>
<li>
The rows are in the order of &quot;2N&quot;
</li>
<li>
You have to sum them up, and you can do this pairwise.
</li>
</ul></li>
<li><p>
If you do <em>n</em> times an operation which costs <em>n</em>, your runtime is going to be <span class="math">\(n^2\)</span>.
</p>

<ul>
<li>
Multiplication is more expensive than addition.
</li>
<li>
Multiplication is quadratic, where addition is linear (with respect to the size of the input).
</li>
</ul></li>
</ul>

<h3>
Alternative Multiplication
</h3>

<ul>
<li><p>
If you have two decimal numbers, <em>x</em> and <em>y</em>, write them next to each other.
</p>

<pre><code>11           13
5            26
2   IGNORE   52
1            104
----------------
            143 (= 13 + 26 + 104)
</code></pre></li>
<li><p>
Notice that the third row is ignored in both varieties of multiplication.
</p></li>
</ul>

<!--    $$ x \times y =\begin{cases} 2 (x \times \lfloor \frac{y}{2} \rfloor, & \text{if $y$ is even}.\\ x + 2(x \times \lfloor \frac{y}{2} \rfloor, & \text{if $y$ is odd}. \end{cases} $$
-->

<ul>
<li>
<p>The expensive operation is the addition if <span class="math">\(y\)</span> is odd. So O(n) due to addition.</p>
<ul>
<li>
Again, big-O is quadratic.
</li>
</ul></li>
</ul>

<h3>
Modula Arithmetic
</h3>

<p>
<span class="math">\[ O(n) \]</span>
</p>

<h3>
Modulo Multiplication
</h3>

<ul>
<li>
<p>The product can be in the order of <span class="math">\((N - 1)^2\)</span>.</p>
<ul>
<li>
The product will be at most <em>2N</em> bits long.
</li>
</ul></li>
</ul>

<p>
<span class="math">\[ O(n^2) \]</span>
</p>

<h3>
Problems
</h3>

<dl>
<dt>
Primality
</dt>
<dd>
<p>
Given a number N, determine whether it is prime.
</p>
</dd>

<dt>
Factorning
</dt>
<dd>
<p>
Given a number N, express it as a product of prime numbers.
</p>
</dd>
</dl>

<h2>
January 29th, 2014 <small>Recitation</small>
</h2>

<h3>
Asymptotic Bounds
</h3>

<ul>
<li>
<p>There are three types we'll use</p>
<ol>
<li>
Tight bound
</li>
<li>
Lower bound
</li>
<li>
Upper bound, &quot;big O&quot;
</li>
</ol></li>
</ul>

<h4>
Upper Bound (Big-O)
</h4>

<p>
<span class="math">\[f(n) = O(g(n))\]</span>
</p>

<blockquote>
  <p>
G is upper upper bound for F if and only if there exists a constant and <span class="math">\(n_0\)</span> such that:
</p>
  
<p>
$ 0 f(n) c g(n) $
</p>
</blockquote>

<p>
<strong>O(f) grows no faster than ..</strong>
</p>

<h4>
Lower Bound (Big Omega)
</h4>

<p>
<span class="math">\[f(n) = \Omega(g(n))\]</span> <span class="math">\[\exists c, n_0 (0 \le c g(n) \le f(n) \forall n \ge n_o)\]</span>
</p>

<p>
<strong>O(f) grows faster than ...</strong>
</p>

<h4>
Tightly Bound (Big Theta)
</h4>

<p>
<strong>O(f) grows equal to</strong>
</p>

<h3>
Runtimes
</h3>

<table>
<thead>
<tr>
  <th>
Name
</th>
  <th>
Function
</th>
</tr>
</thead>
<tbody>
<tr>
  <td>
Logarithmic
</td>
  <td>
<em>O(log(n))</em>
</td>
</tr>
<tr>
  <td>
Constant
</td>
  <td>
<em>O(n)</em>
</td>
</tr>
<tr>
  <td>
Power
</td>
  <td>
<span class="math">\(O(n^a)\)</span>
</td>
</tr>
<tr>
  <td>
Exponential
</td>
  <td>
<span class="math">\(O(a^n)\)</span>
</td>
</tr>
</tbody>
</table>

<h2>
January 31st, 2014 <small>Lecture</small>
</h2>

<ul>
<li>
<p>All cryptography is based on number theory and number theoretic properties.</p>
<ul>
<li>
Think of message as modulo <em>N</em>.
</li>
<li>
Longer message can be broken into smaller pieces.
</li>
<li>
What is a good value for <em>N</em>?
</li>
</ul></li>
</ul>

<h3>
Property
</h3>

<ul>
<li><p>
Pick any two primes, and lets call them <em>p</em> and <em>q</em>.
</p>

<ul>
<li>
Then let <em>N</em> be their product, <em>N</em> = <em>p</em> * <em>q</em>.
</li>
<li>
For any <em>e</em> so that gcd(e, (p - 1)(q - 1)) = 1
</li>
<li><p>
Then the following are true:
</p>

<ol>
<li><p>
Take a number x and think of it as your message in your communication, then <span class="math">\(x \to x^e\)</span> is a bijection.
</p>

<ul>
<li>
An a bijection is a one-to-one mapping.
</li>
</ul></li>
<li><p>
Let <span class="math">\(d = e^{-1} mod (p - 1)(q - 1)\)</span>, then,
</p>

<p>
<span class="math">\[\forall x \in [0, N - 1] (x^e)^d \equiv x mod N\]</span>
</p></li>
</ol></li>
</ul></li>
</ul>

<h4>
Example
</h4>

<ul>
<li><p>
Lets say our two prime numbers are p = 5, q = 11.
</p>

<ul>
<li>
Our N = pq = 55.
</li>
<li><p>
Now we need to find e such that gcd(e, (5 - 1)(11 - 1)).
</p>

<ul>
<li>
So the <abbr title="Greatest common divisor">GCD</abbr> is 1.
</li>
</ul></li>
<li><p>
So lets pick e = 3 is sufficient??
</p>

<ul>
<li><p>
So what is the valye of d?
</p>

<p>
<span class="math">\[d \equiv e^{-1} \bmod (p - 1)(q - 1) \equiv 3^{-1} \bmod 40 \]</span>
</p></li>
</ul></li>
<li><p>
This means that 3 times d is equal to modulo 40, which is the modular inverse.
</p>

<ul>
<li>
For d = 27, we have 3 times 27 which equals 81 or modulo 40.
</li>
</ul></li>
<li><p>
For any message, x modula 55, ecryption is
</p>

<p>
<span class="math">\[ y = x^3 \bmod 55 \]</span>
</p></li>
<li><p>
For any message, decryption is
</p>

<p>
<span class="math">\[ x = y^{27} \bmod 55 \]</span>
</p></li>
</ul></li>
</ul>

<h3>
Proof of property
</h3>

<ul>
<li><p>
We have to show that
</p>

<p>
<span class="math">\[(x^e)^d \bmod N \equiv x \bmod N \]</span>
</p>

<ul>
<li><p>
The following are true if e and d have been selected as specific
</p>

<p>
<span class="math">\[ e \times d \equiv 1 \bmod (p - 1)(q - 1) \equiv e \times d = k (p - 1)(q - 1) + 1 \]</span>
</p></li>
</ul></li>
</ul>

<blockquote>
  <p>
<strong>Fermat's Little Theorem</strong>: If <em>p</em> is prime, then <span class="math">\(\forall 1 \le a \le p\)</span>:
</p>
  
<p>
<span class="math">\(a^p \equiv a \bmod p\)</span> <span class="math">\(a^{p -1} \equiv 1 \bmod p\)</span>
</p>
</blockquote>

<h3>
Summary of RSA
</h3>

<h4>
Bob
</h4>

<ol>
<li><p>
Pick two prime numbers, this is the <em>p</em> and <em>q</em>
</p>

<ul>
<li>
And for the security of the system, pick two <em>large</em> primes.
</li>
</ul></li>
<li><p>
You announce to the world that everyone should be sending your message, that is, publish (N, e) where N equals p times q and e relative prime to (p - 1)(q - 1).
</p></li>
<li>
<p>Internally compute the private key, which is d equal the inverse of e module (p - 1)(q - 1).</p>
<ul>
<li>
If you mulitply the two and modulo product, the value should be one.
</li>
</ul></li>
</ol>

<h4>
Alice
</h4>

<ol>
<li>
Generate encrypted message <span class="math">\(x^e \bmod N\)</span> where e and N come from Bob public key.
</li>
<li>
When Bob receives this message <span class="math">\(x = y^d \bmod N\)</span>.
</li>
</ol>

<h3>
Why is this secure?
</h3>

<ul>
<li><p>
To break the system, Eve must be able to compute x that has never left Alice given the publically available information, and the public key (N, e).
</p>

<ul>
<li>
<p>How do you do this?</p>
<ul>
<li>
Try to guess x so that <span class="math">\(y = x^e\)</span>
</li>
</ul></li>
</ul></li>
<li><p>
Alternatively, she can try to factor out p and q from N, hence, the intractable factoring problem.
</p></li>
</ul>

<h3>
Analysis
</h3>

<blockquote>
  <p>
What are the operations of RSA and what is the running time?
</p>
</blockquote>

<ul>
<li>
Modular exponentiation, plus the decoding.
</li>
<li>
We have to select e, a small integer, but it has to be a relative prime
</li>
<li>
Compute <span class="math">\(d = e^{-1} \bmod (p - 1)(q - 1)\)</span> which always exists when <span class="math">\(e\)</span> is a relative prime.
</li>
<li>
Pick 2 large prime numbers.
</li>
</ul>

<h2>
February 7th, 2013 <small>Lecture</small>
</h2>

<h3>
RSA
</h3>

<ul>
<li><p>
Pick 2 large <em>n</em>-bit primes.
</p>

<p>
<span class="math">\[ N = pq \]</span>
</p>

<p>
<span class="math">\[ e : \gcd(e, (p - 1), (q - 1)) = 1 \]</span>
</p>

<p>
<span class="math">\[ d : d = e^{-1} \bmod (p - 1) (q - 1) \]</span>
</p></li>
</ul>

<h3>
Greatest Common Divisor
</h3>

<ul>
<li>
<p>If you could perform factoring efficiently, the you could solve the problem.</p>
<ul>
<li>
But we do not have one. So RSA is safe.
</li>
</ul></li>
</ul>

<dl>
<dt>
Euclid's observation
</dt>
<dd>
<p>
<span class="math">\(\gcd(x, y) = \gcd(x \bmod  y, y)\)</span>
</p>

<pre><code>function euclid(a, b) {
    if (b == 0) {
        return a;
    } else {
        return euclid(b, a \bmod b);
    }
}
</code></pre>
</dd>
</dl>

<h2>
February 12th, 2014 <small>Lecture</small>
</h2>

<h3>
Review of RSA
</h3>

<ul>
<li>
<p>Sender</p>
<ul>
<li>
Picks two random primes <em>p</em> and <em>q</em>.
</li>
<li>
Sets <em>N</em> equal to <em>pq</em>.
</li>
<li>
<code>gcd(e, (p - 1)(q - 1))</code>
</li>
</ul></li>
</ul>

<blockquote>
  <p>
<strong>Fermat</strong>: If a number <em>p</em> is prime, then for all smaller numbers, it is the case that <span class="math">\(a^{p - 1} \equiv 1 \mod p\)</span>
</p>
</blockquote>

<ul>
<li><p>
How probable is it that this test succeeds? Less than half.
</p></li>
<li><p>
A way of generating random primes
</p>

<ul>
<li>
Pick a random number.
</li>
<li>
Apply the primality test accounrd to Fermat.
</li>
<li>
If it succeeds, then return it.
</li>
</ul></li>
<li><p>
Good news:
</p>

<ul>
<li>
Prime numbers are abundant, frequently arising.
</li>
<li>
A random <em>n</em>-bit number has roughly <span class="math">\(\frac{1}{n}\)</span> chance of being prime.
</li>
</ul></li>
</ul>

<blockquote>
  <p>
<strong>Lagrange's Prime Number Theorem</strong>: Let <span class="math">\(\pi(x)\)</span> be the number of primes <span class="math">\(\le x\)</span>.
</p>
  
<p>
<span class="math">\[ \pi(x) \approx \frac{x}{\ln(x)} \]</span>
</p>
  
<p>
Or more precisely,
</p>
  
<p>
<span class="math">\[ \lim_{x \to \infty} \frac{\pi(x)}{\frac{x}{\ln(x)}} = 1 \]</span>
</p>
</blockquote>

<h3>
Hashing <small>Another Application of Number-Theoretic Algorithms</small>
</h3>

<ul>
<li><p>
<strong>Objective</strong>: Store and efficiently retrieve IP addresses of the form <code>128.32.168.80</code>.
</p>

<ul>
<li>
There are <span class="math">\(2^{32}\)</span> possibilities.
</li>
</ul></li>
<li><p>
Let's say you have <em>n</em> of them (<span class="math">\(n &amp;lt;&amp;lt; 2^{32}\)</span>).
</p></li>
<li><p>
One possible way of storing them is an <em>array</em> of 2 to the 32 size that indicates whether an IP address is in the set <em>n</em> IP addresses.
</p></li>
<li><p>
Another possibility is a <em>linked list</em>, where you only store the <em>n</em> IP addresses.
</p>

<ul>
<li>
But <em>O(n)</em> time to access them.
</li>
</ul></li>
<li><p>
Hash tables try to provide a trade-off.
</p>

<ul>
<li>
Create an array in the order of <em>n</em>.
</li>
</ul></li>
<li><p>
We need hash function that can return an index to the array and have the following properties:
</p>

<ul>
<li>
<p>The function will scatter the elements in the array, it will be &quot;random&quot; where they're going to be placed.</p>
<ul>
<li>
If your given the same placement, you should get the same value.
</li>
<li>
Consistency for the same input, it should always return the same index in the array.
</li>
</ul></li>
</ul></li>
<li><p>
Picking one of the four numbers can work as a hash function under the assumption that that input is uniformly distributed.
</p></li>
<li>
<strong>Objective</strong>: Regardless of the input, we need the &quot;random&quot; property.
</li>
<li>
<strong>Realization</strong>: There is no single hash function that behaves well on all input data.
</li>
<li><p>
<strong>Idea</strong>: Pick from a family of hash functions randomly so that the probability of 2 elements to be mapped to the same index is $  $ size of the array.
</p></li>
<li><p>
Every IP address is a tuple : $ x_1, x_2, x_3, x_4 $ where $ x_1 $.
</p>

<ul>
<li><p>
Consider the has function
</p>

<p>
<span class="math">\[ h_\alpha (x_1, x_2, x_3, x_4) = \sum_{i = 1}^{4} \alpha_1 \times x_i \mod N \]</span>
</p>

<p>
If you pick the numbers alpha-1 at random, then <span class="math">\(h_\alpha\)</span> is likely to be good.
</p></li>
</ul></li>
<li><p>
<strong>Property</strong>: Consider any 2 elements <em>x</em>-1 through <em>x</em>-4 and corresponding <em>y</em>s. If the coefficients are chosen and uniformly at random mod <em>N</em>, then
</p></li>
</ul>

<h2>
February 12th, 2014 <small>Recitation</small>
</h2>

<h3>
Probability Theorem
</h3>

<ul>
<li>
<p>If you have event <em>A</em>, and you want to measure how <em>probable</em> this event is.</p>
<ul>
<li>
We have some axioms. The axioms of probability.
</li>
</ul></li>
</ul>

<blockquote>
  <ol>
  <li>
$ 1 P(A) 0 <span class="math">\(&lt;/li&gt;   &lt;li&gt;\)</span> P(S) = 1 <span class="math">\(&lt;/li&gt;   &lt;li&gt;\)</span> P(A B) = P(A) + P(B)$ if <em>A</em> and <em>B</em> are mutually exclusive.
</li>
  </ol>
</blockquote>

<h4>
Event of throwing a dice
</h4>

<ul>
<li>
<strong>Output</strong>: {1, 2, 3, 4, 5, 6}
</li>
<li>
The probability of any individual role is one in six.
</li>
<li>
The events are independant.
</li>
<li>
The event can be mutually exclusive (with themselves).
</li>
</ul>

<h4>
Bayes Theorem
</h4>

<blockquote>
  <p>
<strong>Bayes' Theorem</strong>:
</p>
  
<p>
<span class="math">\[ P(A | B) = \frac{P(B | A) \times P(A)}{P(B)} \]</span>
</p>
</blockquote>

<h2>
February 14th, 2014 <small>Lecture</small>
</h2>

<h3>
Divide and Conquer Algorithms
</h3>

<ul>
<li><p>
What is the characteristic here?
</p>

<ul>
<li>
Break your problem into smaller instances.
</li>
<li>
In the case of the number-theoretic algorithms, the way we were evaluating the run-time was with bits.
</li>
<li>
Then, recursively solve smaller sub-problems and then combine these answers.
</li>
</ul></li>
<li><p>
What was the recursively algorithm for multiplication? It was already an instance of <em>divide and conquer</em>.
</p>

<ul>
<li>
Before for multiplcation, the running time had a big-O of &quot;n-squared&quot;
</li>
</ul></li>
</ul>

<h4>
New Multiplication
</h4>

<ul>
<li><p>
Now we'll get a better running time for multiplication, with <em>another idea for multiplcation.</em>
</p>

<ul>
<li><p>
Cnosider the following way of writing numbers:
</p>

<ul>
<li><p>
<em>x</em> is written as two numbers, with <em>x</em> &quot;sub left&quot; and <em>x</em> &quot;sub right&quot;, where if it's 10 bits, you have two five bit numbers.
</p>

<p>
<span class="math">\[ x = 2^{\frac{n}{2}} \times x_L + x_R \]</span> <span class="math">\[ y = 2^{\frac{n}{2}} \times y_L + y_R \]</span> <span class="math">\[ x \times y = (2^{\frac{n}{2}} \times x_L + x_R)(2^{\frac{n}{2}} \times y_L + y_R) \]</span>
</p></li>
</ul></li>
</ul></li>
<li><p>
Lets think about the new operations and how much they cost.
</p>

<ul>
<li><p>
In the above representation, we have:
</p>

<ul>
<li>
Additions (linear)
</li>
<li>
Multiplecation with powers of 2 (linear)
</li>
<li>
Four multiplications between &quot;n over two&quot; bit numbers where we call recursively the same operation.
</li>
</ul></li>
<li><p>
We can define a recursive relation:
</p>

<p>
<span class="math">\[ T(n) = 4 \times T(\frac{n}{2}) + O(n) \]</span>
</p></li>
</ul></li>
<li><p>
Gauss observation reowkred the above expression so as to make use of only 3 of the &quot;n over two&quot; multiplications.
</p></li>
<li><p>
At the <span class="math">\((log_2 n\)</span>)^{2n}$ level, we get down to size-1.
</p>

<ul>
<li>
At each level we have <span class="math">\(3^k\)</span> subproblems, each of them of size <span class="math">\(\frac{n}{2^k}\)</span>
</li>
<li>
At each level you have a linear cost for combining the subproblems.
</li>
<li><p>
At depth <em>k</em>,
</p>

<p>
<span class="math">\[ 3^k \times O(\frac{n}{2^k}) = (\frac{3}{2})^k \times O(n)\]</span>
</p></li>
<li><p>
Now, we've managed to decrease the run-time to something like <em>n</em> to-the 1.59 as opposed to <em>n</em>-squared.
</p></li>
</ul></li>
<li><p>
We are solving multiplication with a divide-and-conquer approach.
</p>

<ul>
<li>
By decreasing the number of recursive calls, we managed to get a running time that is <em>better</em>, i.e. the branching factor in terms of recursive calls matters.
</li>
<li><p>
As a matter of fact, when you have something like ...
</p>

<p>
<span class="math">\[ T(n) = \alpha \times T(\frac{n}{b}) + O(n^d) \]</span>
</p></li>
</ul></li>
</ul>

<h3>
Sorting Problems
</h3>

<blockquote>
  <p>
<strong>Master theorem</strong>: If you have a recurisve cost-function of the form <span class="math">\(T(n) = a \times T(\frac{n}{b}) + O(n^2)\)</span> then:
</p>
</blockquote>

<!-- $$ T(n) =   \begin{cases} O(n^d) & \text{if } d \lt log_b a \\ O(n^d \log(n)) & \text{if } d = \log_b a \\ O(n^{log_b a} & \text{if } d \lt log_b a \end{cases} $$
-->

<ul>
<li><p>
Assume that <em>n</em> is a power of <em>b</em> for convinience.
</p>

<ul>
<li>
The size of the problem decreases by <em>b</em> at every level.
</li>
</ul></li>
<li><p>
We need <span class="math">\(log_b n\)</span> level to stop the recursion.
</p>

<ul>
<li><p>
At level <em>k</em> we have <span class="math">\(a^k\)</span> subproblems of size <span class="math">\(\frac{n}{b^k}\)</span>
</p>

<ul>
<li><p>
Work at level <em>k</em>:
</p>

<p>
<span class="math">\[ a^k \times O((\frac{n}{b^k})^d) = O(n^d) \times (\frac{a}{b^d})^k \]</span>
</p></li>
</ul></li>
</ul></li>
</ul>

<h4>
Three cases
</h4>

<ol>
<li><p>
If <span class="math">\(\frac{a}{b^d} \lt 1\)</span>, series is decreasing.
</p>

<ul>
<li>
The &quot;first term&quot; dominates.
</li>
<li><p>
Running time:
</p>

<p>
<span class="math">\[ O(n^d) \]</span>
</p></li>
</ul></li>
<li><p>
If <span class="math">\(\frac{a}{b^d} \gt 1\)</span>, series is increasing
</p>

<ul>
<li>
The &quot;last term dominates&quot;
</li>
<li><p>
Running time:
</p>

<p>
<span class="math">\[ O(n^{\log_b a}) \]</span>
</p></li>
</ul></li>
<li><p>
If <span class="math">\(\frac{a}{b^d} = 1\)</span>, all terms are equivilent.
</p>

<p>
<span class="math">\[ O(n^d) = O(n^{\log_b a}) \]</span>
</p></li>
</ol>

<h2>
February 16th, 2014 <small>Reading</small>
</h2>

<h3>
Chapter 1 <small>Algorithms with numbers</small>
</h3>

<dl>
<dt>
Factoring
</dt>
<dd>
<p>
Given a number <em>N</em>, express it as a product of its prime factors.
</p>
</dd>

<dt>
Primality
</dt>
<dd>
<p>
Given a number <em>N</em>, determine whether it is a prime.
</p>
</dd>
</dl>

<ul>
<li><p>
Factoring is hard.
</p>

<ul>
<li>
Despite lots of effot, the fastest method is exponetial to the number of bits.
</li>
</ul></li>
<li><p>
We <em>can</em> efficiently test whether something <em>is</em> prime!
</p></li>
</ul>

<h4>
Basic arithmetic
</h4>

<h5>
Addition
</h5>

<blockquote>
  <p>
<strong>Basic property of decimal numbers</strong>: The sum of any three single-digit numbers is <em>at most</em> two digits long.
</p>
</blockquote>

<ul>
<li><p>
This simple rule gives us a way to add two numbers in any base:
</p>

<ul>
<li><p>
Align their right-hand ends, and then perform single right-to-left pass in which the sum in which the sum is computed digit-by-digit, maintaining the overflow as a carry.
</p>

<ul>
<li><p>
Since we know each individual sum is a two-digit number, <em>the carry is always a single digit</em>, and so at any given step, three single digit numbers are added.
</p>

<pre><code>Carry: 1        1  1  1     
          1  1  0  1  0  1  (53)
          1  0  0  0  1  1  (35)
       -------------------
       1  0  1  1  0  0  0  (88)
</code></pre></li>
</ul></li>
</ul></li>
<li><p>
<em>Given two binary numbers, how long does our algorithm take to add them?</em>
</p>

<ul>
<li><p>
We want the answer expressed as a function of <em>the size of input</em>.
</p>

<ul>
<li>
The number of bits.
</li>
</ul></li>
<li><p>
Suppose that <em>x</em> and <em>y</em> are <em>n</em> bits longs.
</p>

<ul>
<li>
The the sum of <em>x</em> and <em>y</em> is <em>n + 1</em> bits <em>at most</em>.
</li>
<li>
Each bit of the sum is computed in a fixed amount of time.
</li>
<li>
<p>The total running time for addition:</p>
<ul>
<li>
Of the form <span class="math">\(c_0 + c_1 n\)</span> where &quot;c-zero&quot; and &quot;c-one&quot; are some constant.
</li>
<li>
In other words, it is <em>linear</em>.
</li>
<li>
The running time is <em>O(n)</em>.
</li>
</ul></li>
</ul></li>
</ul></li>
<li><p>
<em>Is there a faster algorithm?</em>
</p>

<ul>
<li>
In order to add two <em>n</em>-bit numbers, we must at least read them and write down the answer, and even that requires <em>n</em> operations.
</li>
<li>
The algorithm is optimal, up to multiplicative constants!
</li>
</ul></li>
<li><p>
<em>Why O(n) operations? Isn't binary addition done in one instruction?</em>
</p>

<ol>
<li><p>
Only addition operations that are within a computers word-length, often 32 or 64.
</p>

<ul>
<li>
It is often useful and necessary to handle number much larger than this, several thousand bits long.
</li>
<li>
Operations on these big numbers is often like operating bit-by-bit.
</li>
</ul></li>
<li><p>
When we want to understand algorithms, it makes sense to study the basic algorithms that encoded to the hardware.
</p>

<ul>
<li>
Focus on <em>bit complexity</em>.
</li>
</ul></li>
</ol></li>
</ul>

<h5>
Multiplication and division
</h5>

<ul>
<li><p>
The grade-school algorithm for multiplying to numbers is to create an array of intermiediate sums, each representing the product of the first number by a single digit of the second.
</p>

<ul>
<li>
These values are left-shifted and right-shifted and added.
</li>
</ul></li>
<li><p>
Thirteen times eleven in binary:
</p>

<pre><code>            1  1  0  1  (binary 13)
         x  1  0  1  1  (binary 11)
----------------------
            1  1  0  1  (1101 times 1, shifted no)
         1  1  0  1     (1101 times 1, shifted once)
      0  0  0  0        (1101 times 0, shifted twice)
+  1  1  0  1           (1101 times 1, shifted thrice)
----------------------
1  0  0  0  1  1  1  1  (binary 143)
</code></pre></li>
<li><p>
Psuedo code:
</p>

<pre><code>function multiply(x, y) {
    if (y == 0) {
        return 0
    }

    z = multiply(x, floor(y / 2));

    if (y is even) {
        return 2z;
    } else {
        return x + 2z;
    }
}
</code></pre></li>
<li><p>
<em>How long does this take?</em>
</p>

<ul>
<li>
If <em>x</em> and <em>y</em> are both <em>n</em>-bits, then there are <em>n</em> intermediate rows, with lengths of up to <em>2n</em> bits (taking the shiting into account).
</li>
<li><p>
The total time to add up these rows, doing two numbers at a time:
</p>

<p>
<span class="math">\[ O(n) + O(n) + ... + O(n) \]</span>
</p>

<p>
<em>(n - 1)</em> times.
</p>

<ul>
<li>
This is <span class="math">\(O(n^2)\)</span>, or <em>quadratic</em> in the size of the inputs.
</li>
<li>
Still polynomial but much slower than addition.
</li>
</ul></li>
</ul></li>
<li><p>
<em>Can this be improved?</em>
</p>

<ul>
<li>
Al Khwarizmi knew another way to multiple.
</li>
<li><p>
To multiply two decimal numbers, write them next to each other.
</p>

<ul>
<li>
Then, repeat: Divide the first number by 2, rounding down the result, and double the second number. Keep going until the first number gets down to 1.
</li>
<li><p>
Then, strike out all the rows in which the first number is even, and add up whatever remains in the second column.
</p>

<pre><code>11  13
 5  26
 2  52  (strike out)
 1 104
------
   143  (answer)
</code></pre></li>
</ul></li>
</ul></li>
<li><p>
Pseudocode!
</p>

<pre><code>function divide(x, y) {
    if (x == 0) {
        return (q, r) = (0, 0);
    }

    (q, r) = divide(floor(x / 2), y);
    q = 2 * q;
    r = 2 * r;

    if (x is odd) {
        r = r + 1;
    } 

    if (r &gt;= y) {
        r = r - y;
        q = q + 1;
    }

    return (q, r)
}
</code></pre></li>
<li><p>
<em>Is this algorithm correct?</em>
</p>

<ul>
<li>
Verify that it mimics the description of the rules.
</li>
</ul></li>
<li><p>
<em>How long does this algorithm take?</em>
</p>

<ul>
<li><p>
It must terminate after <em>n</em> recursive calls, because at each call <em>y</em> is halved.
</p>

<ul>
<li>
That is, the number of bits is decreased by one.
</li>
</ul></li>
<li><p>
Each recursive call requires these operations:
</p>

<ul>
<li>
A division by 2 (right shift)
</li>
<li>
A test for odd/even (looking up the last bit)
</li>
<li>
A multiplication by 2 (left shift)
</li>
<li>
Possible on addition, O(n).
</li>
</ul></li>
<li><p>
The total time is <span class="math">\(O(n^2)\)</span> therefore.
</p></li>
</ul></li>
<li><p>
<em>Can we do better?</em>
</p>

<ul>
<li>
Intuitively, you think that you need to, at most, do <em>n</em> operations <em>n</em> times to add.
</li>
<li>
But no! Chapter 2 will show you can do better.
</li>
</ul></li>
</ul>

<h4>
Modular arithmetic
</h4>

<ul>
<li><p>
With repeated addition or multiplication, numbers get very big.
</p>

<ul>
<li>
We &quot;reset to zero&quot; whenever time reaches 24.
</li>
<li>
Similarly, the built-in arithmetic operations of computer processors, numbers are restricted to a size, say 32 or 64, which is generous for most purposes.
</li>
</ul></li>
<li><p>
For primality testing and cryptography, it is necessary to deal with numbers that are significantly bigger.
</p></li>
<li>
<em>Modular arithmetic</em> is a system for dealing with restricted ranges of integers.
</li>
</ul>

<dl>
<dt>
<em>x</em> <em>modulo</em> <em>N</em>
</dt>
<dd>
<p>
The remainder when <em>x</em> is divided by <em>N</em>.
</p>

<p>
If <em>x = qN + r</em> with <em>0 &lt;= r &lt; N</em>, then <em>x</em> modulo <em>N</em> is equal to <em>r</em>.
</p>
</dd>
</dl>

<ul>
<li><p>
One way to think of modular arithmetic deals with all the integers, but divides them in <em>N</em> <em>equivilence classes</em>, each of the form $ i + kN : k  $ for some <em>i</em> between ) and <em>N - 1</em>.
</p>

<ul>
<li><p>
For example, there are three equivilence classes of modulo 3:
</p>

<pre><code>...  -9  -6  -3  0  3  6  9  ...
...  -8  -5  -2  1  4  7  10 ...
...  -7  -4  -1  2  5  8  11 ...
</code></pre>

<p>
Any member of the class is substituable for any other.
</p></li>
</ul></li>
</ul>

<blockquote>
  <p>
<strong>Substitution rule</strong>: If $ x x' ( N)$ and <span class="math">\(y \equiv y&#39; (\bmod N)\)</span>, then:
</p>
  
<p>
<span class="math">\[ x + y \equiv x&#39; + y&#39; (\bmod N) \]</span>
</p>
  
<p>
<span class="math">\[ xy \equiv x&#39; y&#39; (\bmod N) \]</span>
</p>
</blockquote>

<ul>
<li><p>
It is not hard to check that in modular arithmetic, the usual associate, commutative, and distributive properties of addition and multiplication continue to apply.
</p>

<ul>
<li><p>
For instance:
</p>

<ul>
<li>
Associativity
</li>
<li>
Commutativity
</li>
<li>
Distributivity
</li>
</ul></li>
<li><p>
You can simplify big numbers with this. Witness:
</p>

<p>
<span class="math">\[ 2^{345} \equiv (2^5)^{69} \equiv 32^{69} \equiv 1^69 \equiv 1 (\bmod 31) \]</span>
</p></li>
</ul></li>
</ul>

<h5>
Modular addition and multiplication
</h5>

<ul>
<li><p>
To <em>add</em> two numbers &quot;<em>x</em> and <em>y</em> modulo <em>N</em>&quot;, we start with regular addition.
</p>

<ul>
<li>
Since <em>x</em> and <em>y</em> are both in the range of 0 to <em>N - 1</em>, their sum is between <em>0</em> and <em>2(N - 1)</em>.
</li>
<li>
If the sum exceeds <em>N - 1</em>, we merely need to subtract of <em>N</em> to bring it back to the required range.
</li>
<li>
The overal computation therefore consists of an addition, and possibly a substraction, of numbers that never exceed <em>2N</em>.
</li>
<li>
<p>Its running time is linear in the sizes of these numbers.</p>
<ul>
<li>
In other words, <em>O(n)</em>, where <em>n = ceil(log N)</em>, is the size of <em>N</em>.
</li>
</ul></li>
</ul></li>
<li><p>
To <em>multiply</em> two mod-<em>N</em> numbers <em>x</em> and <em>y</em>, we again just start with regular multiplication and then reduce the answer modilo <em>N</em>.
</p>

<ul>
<li><p>
The produce can be as large as <span class="math">\((N - 1)^2\)</span>.
</p>

<ul>
<li>
But this is still at most <em>2n</em> bits long.
</li>
</ul></li>
<li><p>
To recude the answer modulo <em>N</em>, we compute the remainder upon dividing it by <em>N</em>, using our quadratic-time division algorith,
</p></li>
<li>
Multiplication remains a quadratic operation.
</li>
</ul></li>
<li><p>
<em>Division</em> is not so easy.
</p>

<ul>
<li>
Will be do later.
</li>
</ul></li>
<li><p>
To complete the suit of modular arithmetic primitives we need for cryptography, we next turn to <em>modular exponentiation</em>, and then to <em>greatest common divisor</em>, which is the key to division.
</p></li>
</ul>

<h5>
Modular exponentiation
</h5>

<ul>
<li><p>
<em>What is the algorithm?</em>
</p>

<pre><code>function modular-exponentiation(x, y, N) {
    if (y == 0) {
        return 1;
    }

    z = modulor-exponentiation(x, floor(y / 2), N);

    if (y is even) {
        return (z ** 2) % N;
    } 

    else {
        return (x * (z ** 2)) % N;
    }
}
</code></pre></li>
<li><p>
In the cryptosystem we are working towards, it is necessary to compute &quot;<em>x</em> to the <em>y</em> mod <em>N</em>&quot; for the values of <em>x</em>, <em>y</em>, and <em>N</em> that are several hundred bits long. <em>How can this be done quickly?</em>
</p></li>
<li><p>
The result is some number modulo <em>N</em> and is therefore itself a few hundred bits long.
</p>

<ul>
<li>
<p>However, the raw value of &quot;<em>x</em> to the <em>y</em>&quot; could be much, much longer than this.</p>
<ul>
<li>
Even when <em>x</em> and <em>y</em> are just 20-bit numbers, &quot;<em>x</em> to the <em>y</em>&quot; is <em>at least</em> <span class="math">\((2^{19})^{2^{19}} = 2^{(19)(524288)}\)</span>, about 10 million bits long!
</li>
</ul></li>
</ul></li>
<li><p>
To make sure the numbers we are dealing with never grow too large, we need to perform all intermediate computations modulo <em>N</em>.
</p>

<ul>
<li><p>
Here's the idea:
</p>

<ul>
<li><p>
Calculate <span class="math">\(x^y \bmod N\)</span> by repeatedly multiplying by <em>x</em> modulo <em>N</em>. The resulting sequence of intermediate products,
</p>

<p>
<span class="math">\[ x \bmod N \to x^2 \bmod N \to x^3 \bmod N \to ... \to x^y \bmod N \]</span>
</p>

<p>
consists of number that are smaller than <em>N</em>, and so the individual multiplications do not take too long.
</p></li>
<li>
But there's a problem! If <em>y</em> is 500 bits long, we need to perform &quot;2 to the 500&quot; multiplication! The algorithm is clearly exponetial in the size of <em>y</em>.
</li>
</ul></li>
</ul></li>
<li><p>
Luckily, we can do better.
</p>

<ul>
<li><p>
Starting with <em>x</em> and <em>squaring repeatedly</em> modulo <em>N</em>, we get:
</p>

<p>
<span class="math">\[ x \bmod N \to x^2 \bmod N \to \cdots \to x^{2^{\log y}} \bmod N \]</span>
</p></li>
<li><p>
Each takes <span class="math">\(O(log^2 N)\)</span> to compute, with only <em>log y</em> multiplications.
</p>

<ul>
<li><p>
To determine this, multupli together these powers.
</p>

<p>
<span class="math">\[ x^{25} = x^{11001_2} = x^{10000_2} \times x^{1000_2} \times x^{1_2} = x^{16} \times x^8 \times x^1 \]</span>
</p></li>
<li><p>
A polynomial time algorithm
</p></li>
</ul></li>
</ul></li>
<li><p>
We can package this idea in a simply recusrive algorithm described at this begninng of this section.
</p>

<ul>
<li><p>
Let <em>n</em> be the size of bits <em>x</em>, <em>y</em>, and <em>N</em> (whichever of the three is largest)
</p>

<ul>
<li>
Like multiplication, the algorithm will halt after <em>at most</em> <em>n</em> recursive calls.
</li>
<li>
During each call it multiplies <em>n</em>-bit numbers
</li>
<li>
Doing computation modulo <em>N</em> saves us here.
</li>
</ul></li>
<li><p>
Running time of <span class="math">\(O(n^3)\)</span>
</p></li>
</ul></li>
</ul>

<h5>
Euclids algorithms for greatest common divisor
</h5>

<ul>
<li>
Given to integerns <em>a</em> and <em>b</em>, find the largest integer that divides both of them, known as their <em>greatest common divisor</em> (gcd).
</li>
<li><p>
The most obvious approach is to first factor <em>a</em> and <em>b</em>, and the multiply together their common factors.
</p>

<ul>
<li>
For instance, <span class="math">\(1035 = 3^2 \cdot 5 \cdot 23\)</span> and <span class="math">\(759 = 3 \cdot 11 \cdot 23\)</span>, so their <abbr title="Greatest common divisor">GCD</abbr> is $ 3 23 = 69 $.
</li>
<li>
<p>However, we have no efficient algorithm for factoring.</p>
<ul>
<li>
<em>Is there some other way?</em>
</li>
</ul></li>
</ul></li>
<li><p>
Euclid's algorithm uses the following simple formula.
</p>

<blockquote>
  <p>
<strong>Euclid's rule</strong>: If <em>x</em> and <em>y</em> are positive integers with <span class="math">\(x \ge y\)</span>, then <span class="math">\(\gcd(x, y) = \gcd(x \bmod y, y)\)</span>.
</p>
</blockquote></li>
<li><p>
Euclid's rule allows us to write down an elegant recursive algorithm:
</p>

<pre><code>function Euclid(a, b) {
    if (b == 0) {
        return a;
    }

    return Euclid(b, a % b);

}
</code></pre>

<ul>
<li>
<p>This means that after any two consective rounds, both arguments <em>a</em> and <em>b</em> are <em>at very least</em> halved in value - the length of each decreases by at least on bit.</p>
<ul>
<li>
If they are initially <em>n</em>-bit integers, then the base case will be reached within <em>2N</em> recursive calls.
</li>
<li>
And since each call involves a quadratic-time division, the total time is <span class="math">\(O(n^3)\)</span>.
</li>
</ul></li>
</ul></li>
</ul>

<h5>
An extension of Euclid's algorithm
</h5>

<ul>
<li>
A small extensions is the key to dividing in the modular world.
</li>
<li><p>
Suppose someone claims that <em>d</em> is the <abbr title="Greatest common divisor">GCD</abbr> of <em>a</em> and <em>b</em>:
</p>

<ul>
<li>
How can we check this?
</li>
</ul>

<blockquote>
  <p>
<strong>Lemma</strong>: If <em>d</em> divides both <em>a</em> and <em>b</em>, and <em>d = ax + by</em> for some integers <em>x</em> and <em>y</em>, then necessarily <em>d = gcd(a, b)</em>.
</p>
</blockquote></li>
<li><p>
So, if we can supply two numbers <em>x</em> and <em>y</em> such that <em>d = ax + by</em>, then we can be sure that <em>d = gcd(a, b)</em>.
</p>

<ul>
<li>
What is even better is that those <em>x</em> and <em>y</em>s can be found by a small extension of Euclid's algorithm.
</li>
</ul>

<blockquote>
  <p>
<strong>Lemma</strong>: For any positive integers <em>a</em> and <em>b</em>, the extended Euclid algorithm returns integers <em>x</em>, <em>y</em>, and <em>d</em> such that <em>gcd(a, b) = d = ax + by</em>.
</p>
</blockquote></li>
</ul>

<h4>
Primality testing
</h4>

<h4>
Cryptography
</h4>

<h4>
Universal hashing
</h4> 
{% endraw %}