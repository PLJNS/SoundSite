---
layout: page
title: Notes
subtitle: From Paul Jones at Rutgers University
---
{% raw %}
<h1 id="survey-in-epistemology-with-professor-alvin-goldman">Survey in Epistemology <small>with Professor Alvin Goldman</small></h1>
<h2 id="september-8th-2013-chapter-1-the-structure-of-justification">September 8th, 2013 <small>Chapter 1, 'The Structure of Justification'</small></h2>
<h3 id="the-concepts-and-questions-of-epistemology">The Concepts and Questions of Epistemology</h3>
<ul>
<li>Epistemology is the study of knowledge and related phenomena.</li>
<li>Why is this important?
<ul>
<li>It can lead to better decisions.</li>
</ul></li>
<li>How do we get truths? <strong>Justification</strong>.
<ul>
<li>A justified or warranted belief is more likely to be true.</li>
<li>A randomly or haphazardly chosen belief is less likely to be true.</li>
<li>So how do we get the first?</li>
</ul></li>
<li>What is a belief (alternatively opinion?)
<ul>
<li>It is a <em>psychological attitude towards a proposition</em>.
<ul>
<li>Where a proposition is (roughly) content which purports to be fact.</li>
</ul></li>
<li>To believe is to <em>mentally assent</em> to a propositions.</li>
<li>Possible doxastic attitudes:
<ol style="list-style-type: decimal">
<li><strong>Belief</strong>, to mentally assent.</li>
<li><strong>Disbelief</strong>, to mentally dissent.</li>
<li><strong>Suspension</strong>, to neither assent nor dissent.</li>
</ol></li>
</ul></li>
</ul>
<blockquote>
<p>It is widely thought that forming a belief that is reasonable, warranted, or justified is the best means available of forming a true belief</p>
</blockquote>
<ul>
<li>Epistemic evaluations are different from moral evaluations.
<ul>
<li>They express evaluations on an <em>intellectual dimension</em>.</li>
</ul></li>
<li>Truth and justification are not equivalent.
<ul>
<li>Truth is purely metaphysical.</li>
<li>It is true or false <em>of the world</em>.</li>
<li>You can have a justified false belief.</li>
</ul></li>
<li>Justification is one form of epsitemic evaluation, but perhaps there are others.
<ul>
<li>For instance, rationality may be another, unique or not.</li>
</ul></li>
<li>Some points of widespread agreement:
<ol style="list-style-type: decimal">
<li>Knowledge implies truth;</li>
<li>A person must believe p, or have reasonably high credence in p, in order to know it;</li>
<li>Knowledge requires justification.</li>
</ol></li>
</ul>
<h3 id="the-epistemic-regress-problem">The Epistemic Regress Problem</h3>
<ul>
<li>Many sources of justification are inference.</li>
<li>Justification needn't be spoken.</li>
<li>The structure of justification is a tree, where properly justified beliefs (nodes) inherit justification from roots
<ul>
<li>With roots in truth?</li>
</ul></li>
<li>Where does the original justification come from?
<ul>
<li>This is the <strong>regress problem</strong>.</li>
</ul></li>
<li>Possible solutions:
<ul>
<li><strong>Infinitism</strong>: An unending continuation of reasons, without repetition or end.<br /></li>
<li><strong>Foundationalism</strong>: An ending tree of reasons.</li>
<li><strong>Coherentism</strong>: A tree that loops back on itself.</li>
<li><strong>Skepticism</strong>. None of the first three solutions to the regress problem is satisfactory.</li>
</ul></li>
<li>There are two types of ways of looking at justification with regards to time.
<ul>
<li><strong>Synchronic</strong>: A synchronic reason for a belief happens at the same time as the target belief.</li>
<li><strong>Diachronic</strong>: A diachronic reason is unavailable at the formation of the target belief?</li>
</ul></li>
</ul>
<h3 id="infinitism">Infinitism</h3>
<blockquote>
<p>Infinitism is rarely given serious consideration.</p>
</blockquote>
<ul>
<li>If justification goes back infinitely far, then we hold infinitely many beliefs?
<ul>
<li>No human person has infinitely many beliefs.</li>
</ul></li>
<li>Perhaps justification needn't originate anywhere.</li>
<li>What about with regards to people holding infinitely many beliefs?
<ul>
<li><strong>Doxastic justification</strong> is a property of existing beliefs.</li>
<li><strong>Propositional justification</strong> arises from the state or condition of an epistemic agent that entitles her to believe a proposition.</li>
</ul></li>
</ul>
<blockquote>
<p>infinitism can be interpreted as the view that there are infinitely many propositions (rather than beliefs) that form chains of inferential justification.</p>
</blockquote>
<ul>
<li>This may support foundationalism, however, because if justification isn't (ultimately) a doxastic attitude, then there is an end to the held beliefs which can serve an agent.
<ul>
<li>There is no way that infinitist ghost propositions can be measured without making the propositions becoming beliefs.</li>
</ul></li>
<li>&quot;Justification is limited in RAM, unlimited in HDD storage.&quot;</li>
</ul>
<h3 id="coherentism">Coherentism</h3>
<ul>
<li>Coherentism is a minority view today, but historically important.
<ul>
<li>Largely, the view <em>tolerates circular inference</em>.</li>
<li>&quot;Sometimes circularity is okay.&quot;</li>
</ul></li>
<li>There are no &quot;privileged beliefs&quot; that are tethered to truth, but rather any net of self-supporting justification are valid epistemologically.
<ul>
<li>&quot;Justification is a circularly linked list.&quot;</li>
</ul></li>
<li>Coherence and justifiedness are not intimately linked at all, and coherence and truth are similarly unlinked (thought not for the same reasons, justification and truth are distinct).</li>
</ul>
<h3 id="foundationalism-and-basic-beliefs">Foundationalism and Basic Beliefs</h3>
<blockquote>
<p>Foundationalism’s response to the regress problem says that every root in a tree of (successful) inferential justification terminates after finitely many steps.</p>
</blockquote>
<ul>
<li>Foundational beliefs have two crucial properties:
<ul>
<li>The are <em>uninferred</em>;</li>
<li>They are justified.</li>
</ul></li>
<li>There are four questions that foundationalism must address to succeed:
<ol style="list-style-type: decimal">
<li>Exactly what does it take for a belief to attain the status of &quot;justified&quot; in an unmediated or non-inferential fashion? What must take place or hold true of a belief to confer on it the property of being immediately justified?</li>
<li>Which types of belief or families of belief qualify as immediately justified? What kinds of propositional contents lend themselves to immediate justification?</li>
<li>What strength of justification do immediately justified beliefs need to attain according to foundationalism? Must basic beliefs exhibit the highest grade of justification, i.e., certainty, infallibility, or incorrigibility? Or can basic beliefs have weaker degrees of justification while still being basic?</li>
<li>Assuming that many immediately justified beliefs are available, does this enable epistemic agents to draw enough reasonable inferences that they can attain a large corpus of justified beliefs (both basic and non-basic), enough to dispel the specter of skepticism that is often laid at foundationalism's doorstep?</li>
</ol></li>
</ul>
<h2 id="september-9th-2013-seminar">September 9th, 2013 <small>Seminar</small></h2>
<h3 id="concepts-and-questions">Concepts and Questions</h3>
<ul>
<li>Doxastic attitudes, &quot;Epistemic terms of appraisal&quot;
<ul>
<li>Beliefs, non-belief,</li>
<li>Tripartite approach.</li>
<li>What are others?
<ul>
<li>Degrees of conviction</li>
<li>&quot;High confidence&quot;, expresses a doxastic attitude, on a range of attitudes.</li>
</ul></li>
<li>It's not like desiring, or hating.
<ul>
<li>It's an attitude about truth or falsity.</li>
<li>An &quot;intellectual&quot; attitude.</li>
<li>Abstaining from being committal.</li>
</ul></li>
</ul></li>
<li>Are beliefs epistemic states?
<ul>
<li>Lots of philosophers talk about beliefs as epistemic states.
<ul>
<li>Doxastic attitudes are psychological states.</li>
<li>Epistemic states are evaluations on intellectual dimensions.</li>
</ul></li>
</ul></li>
<li>&quot;Know&quot; is traditionally thought not to be an entirely mental state.
<ul>
<li>It's partly:
<ul>
<li>Having a belief.</li>
<li>Having a justified belief.</li>
<li>And being true.</li>
</ul></li>
<li>Knowledge is a &quot;mental state plus …&quot;
<ul>
<li>Something like justification</li>
<li>An epistemic component.</li>
</ul></li>
</ul></li>
<li>We never want to mix up truth and justification.
<ul>
<li>Justification is limited to an epistemic or doxastic agent.</li>
<li>Justified <em>for whom</em>?</li>
<li>Justified <em>when</em>?</li>
</ul></li>
<li>&quot;You're justified in believing, but you don't.&quot;
<ul>
<li>Propositional justification.</li>
</ul></li>
<li>&quot;You're justified in believing, and you do.&quot;</li>
</ul>
<h3 id="the-regress-problem">The Regress Problem</h3>
<ul>
<li>An inferential regress.</li>
<li>To give a reason is to say something.
<ul>
<li>You might have a reason, but not say it.</li>
</ul></li>
<li>The skeptic thesis:
<ul>
<li>We do not have as many JTBs as we think we do commonsensically.</li>
</ul></li>
<li>If you say we're talking about doxastic justification, then yes, maybe we cannot have infinitely many psychological states.
<ul>
<li>&quot;Propositional justifiedness&quot;</li>
</ul></li>
</ul>
<h3 id="coherentism-1">Coherentism</h3>
<ul>
<li>Was popular in idealism (one or another) in Britain and American dominant.
<ul>
<li>These involved people that are not read anymore.</li>
<li>Royce, Bradley.</li>
<li>Late 19th century.</li>
<li>Very popular</li>
<li>They often talk about in the kind of abstract way that infinitism will be defended.</li>
<li>The methodology was much more abstract.</li>
</ul></li>
<li>There are senses within belief.
<ul>
<li>The belief <em>itself</em>, the psychological action.</li>
<li>The belief's <em>content</em>, the proposition believed.</li>
</ul></li>
<li>We want to distinguish between saying that &quot;<em>p</em> is justified&quot; and &quot;<em>p</em> is justified for <em>S</em> at time <em>t</em>.&quot;
<ul>
<li>The second one is okay and is precise.</li>
<li>The first is not useful in epistemology.</li>
<li>Propositions do not do any justification of their own, propositions are not justified.
<ul>
<li>Beliefs <em>in</em> propositions <em>by</em> agents are justified <em>for them</em>.</li>
<li>You do not get anything from propositional coherence.</li>
</ul></li>
</ul></li>
<li>What's the relationship between rationality and justification.
<ul>
<li>There's no common practice.</li>
</ul></li>
<li>Can coherence account for non-coherent justified beliefs?</li>
</ul>
<h3 id="foundationalism">Foundationalism</h3>
<ul>
<li>Descartes thought that &quot;basic beliefs&quot; (new terminology) are about the agent's mental states.</li>
<li>Well what are basic/immediate beliefs like?
<ul>
<li>Early on, beliefs about mental states.</li>
<li>Later, beliefs from perception.</li>
</ul></li>
</ul>
<h2 id="september-16th-2013-chapter-2-part-i-evidentialism-vs.-reliabilism">September 16th, 2013 <small>Chapter 2, part I, 'Evidentialism vs. Reliabilism'</small></h2>
<ul>
<li><strong>justifier</strong> refers to anything that helps make a belief state justified or unjustified.
<ul>
<li>Anything that contributes to the <strong>justificational status</strong> of a target belief.</li>
</ul></li>
</ul>
<blockquote>
<p>How can one legitimately infer outward (to the external world), forward (to the future), and backward (to the past) from the indicated, very limited, data-set?</p>
</blockquote>
<ul>
<li><strong>Evidentialism</strong>: all (positive or negative) justifiers of a belief held by epistemic agent <em>S</em> at time <em>t</em> are evidential states <em>S</em> is in at <em>t</em>.
<ul>
<li>there must be a relation of <strong>fittingness</strong> that holds between the attitude of belief (directed at <em>P</em>) and <em>S</em>’s total evidential states at <em>t</em>.</li>
<li><em>X</em> is evidence for <em>Y</em> just in case possessing <em>X</em> enhances a person’s justification for believing <em>Y</em>.</li>
</ul></li>
</ul>
<blockquote>
<p>what justifies me in thinking that the fusiform gyrus of my right occipital cortex is being activated is that the fusiform gyrus of my right occipital cortex is being activated</p>
</blockquote>
<ul>
<li><strong>Reliablism</strong>: Belief <em>B</em> is justified if and only <em>B</em> is produced by a reliable belief-forming process, i.e., a process that has a tendency to generate (belief) outputs with a high percentage of truths.</li>
</ul>
<h3 id="questions">Questions</h3>
<ol style="list-style-type: decimal">
<li>pg. 4, &quot;According to evidentialism, all (positive or negative) justifiers of a belief held by epistemic agent S at time t are evidential states S is in at t.&quot; This took a few reads and a cross-check with the Wikipedia to fully understand. Specifically, I didn't know what it meant for S to be &quot;in an evidential state.&quot; When I worked out what that meant, the definition was easily understood.
<ul>
<li>This was supremely cleared up on pg. 7, with the precise formulation of evidentialism, what it implies.</li>
</ul></li>
<li>pg. 10, &quot;Nonetheless, it is perfectly plausible that her belief in this proposition is justified.&quot; This actually happens all the time! It may add something to the credibility and plausibility of the case to name the psychology term for it: Source Amnesia.
<ul>
<li>pg. 11, &quot;it plays no causal role in her current belief in D.&quot; I cannot find anything defined with that variable, thought I think I can reasonably assume it's the claim about the earth.</li>
</ul></li>
<li>pg. 18, &quot;Thus, wishful thinking is “bad” because the beliefs it outputs are only occasionally true.&quot; Wouldn't wishful thinking still be bad even if the beliefs it outputs were more often than not true? It's not clear to me from the example wishful think is bad because of unreliability, but it is certainly unreliable.
<ul>
<li>pg. 18, &quot;The overextended version of disjunctive syllogism is “bad” because it would frequently lead to erroneous conclusions even when the inputs to it are true.&quot; This is closer to my intuition, but all it would take for me to think that it was bad was one case where even one invalid logical schema was used. A good schema is always gets good conclusions for when the inputs are true.</li>
<li>After I read the definition for process reliablism a bit further down along with the suitably vague portion, it seems very plausible for longer belief forming processes like perception (which is vague, which has variable successes and failures), but not so applicable to using bad logic rules. I think the difference is that a bad logic schema has concrete, knowable cases of when it always gets it wrong.</li>
<li>After (CR) and (UR), this was cleared up I think.</li>
</ul></li>
<li>pg. 24, &quot;By contrast, teliabilism seems to secure it easily.&quot; You may or may not have seen this typo, but I'll add it just in case.</li>
</ol>
<h2 id="september-16th-2013-seminar">September 16th, 2013 <small>Seminar</small></h2>
<h3 id="question-time">Question time</h3>
<ul>
<li>Well-foundedness was introduced later by Feldman, it isn't there on the literature of foundationalism or coherentism. &quot;Current-time slice theories.&quot; There can be no longer causal process.
<ul>
<li>There was a tradition in logical positivists, that psychological factors do not belong in justification. Many important philosophers were anti-psychologistic.
<ul>
<li>Influetial idea that the context of discovery, &quot;thinking up&quot; the idea, as opposed to the context of justification. The logic of justification or confirmation, that's one thing, and that's to be studied by formal logic and confirmation theory. Philsophy of science wing of epistemology.</li>
</ul></li>
<li>How you came to believe it is a psychological issue.</li>
<li>It's be chosen because:
<ol style="list-style-type: decimal">
<li>It's influential.</li>
<li>It's a nice contrast to reliablism.
<ul>
<li>Fits nicely internalism/externalism.</li>
</ul></li>
</ol></li>
</ul></li>
<li>The canonical way of talking about doxastic: &quot;<em>p</em> is justified in <em>D</em> for <em>S</em> at <em>t</em>.&quot;
<ul>
<li><em>D</em> could be believing, disbelieving, or suspending justification.</li>
<li>Does this mean <em>S</em> <strong>does</strong> believe it?</li>
<li>Some people definitely think of propositional justification as the main type philosophers are interested in.</li>
</ul></li>
<li>Propositional justification makes it difficult to talk about causal theories.</li>
<li>Propositional justification is defined in terms of doxastic, &quot;If you were to hold this doxastic attitude.&quot;</li>
<li>Most epistemologists think knowledge requires justification.
<ul>
<li>What type?</li>
</ul></li>
<li>On the example of Chad and his poor reasoning
<ul>
<li>I do not think that reliablism gets it right or that it's a problem for evidentialism.</li>
</ul></li>
<li>Some background on evidentialist position:
<ul>
<li>Evidence is always mental states
<ul>
<li>There are experiential mental states.</li>
<li>There are doxastic mental states, belief, disbelief, and suspension.</li>
</ul></li>
<li>If states fit the belief, then the belief is justified.</li>
<li><em>S</em> has <em>D</em> towards <em>p</em> on the basis of <em>E</em>.</li>
<li>Just the states are not alone.</li>
<li>It does not come from the specific case to the general.
<ul>
<li>There is a problem with this generalization thing.</li>
<li>If by virtue of the fact that Chad gets in wrong in these specific circumstances he is not justified in the instances where Chad gets it right, then this is a counterexample to reliablism as well. Imagine Chad gets it right for 3/4 times. This reliably gets the truth. But he is still unjustified because he could have gotten it wrong. (I think, will expand later.)</li>
</ul></li>
</ul></li>
</ul>
<h3 id="presentation-on-evidentialism">Presentation on Evidentialism</h3>
<ul>
<li><strong>Epistemically justified</strong>: Doxastic attitude <em>D</em> towards propositions <em>p</em> is epistemically justified for <em>S</em> at <em>t</em> if and only if having <em>D</em> towards <em>p</em> fits the evidence <em>S</em> has at <em>t</em>.</li>
<li><strong>Well-foundedness</strong>: A belief is well-founded only if:
<ol style="list-style-type: decimal">
<li>It is justified;</li>
<li>It was formed based on a suitable body of evidence.</li>
</ol></li>
<li>There are three different questions according to Conee and Feldman:
<ol style="list-style-type: decimal">
<li>Is she epistemically responsible in believing <em>p</em>?</li>
<li>Is her belief that <em>p</em> well-founded?</li>
<li>Is her belief that <em>p</em> justified?</li>
</ol></li>
</ul>
<h3 id="reliablism">Reliablism</h3>
<ul>
<li>What do you mean by a process?
<ul>
<li>It's maybe not <em>wholly</em> mental.</li>
<li>Does it start with the environment?
<ul>
<li>&quot;He formed the belief about the color of the fruit in queer light.&quot;</li>
</ul></li>
<li>Uncle Floyd and Niece Sally
<ul>
<li>Niece Sally believes Uncle Floyd, it starts with her auditory system, it begins with the input to the auditory system. Start from the inner ear? And then go into the neuro-processing of the ear.</li>
<li>Perhaps it begins with what the person says.</li>
<li>Goldman likes to keep the process on the inside, &quot;skin in.&quot;</li>
</ul></li>
</ul></li>
<li>There are <strong>belief-independent processes</strong> and <strong>belief-dependent processes</strong></li>
</ul>
<h2 id="september-23th-2013-chapter-2-part-ii-internalism-vs.-externalism">September 23th, 2013 <small>Chapter 2, part II, 'Internalism vs. Externalism'</small></h2>
<h3 id="framing-the-debate">Framing the Debate</h3>
<ul>
<li>Evidentialism belongs to internalism
<ul>
<li>While process reliablism belongs to externalism.</li>
<li>They are rivals for what are called &quot;j-factors.&quot;</li>
<li>Externalism claims that all justifying factors are external, internalism thinks they are internal.</li>
<li>Mentalism is a prime example of externalism.</li>
<li>Since truth is a function outside the mind, process reliablism is external.</li>
</ul></li>
<li>Externalism has the air of being the default position because internalism's premise is that <em>all</em> justifying factors are internal to agents, and externalism's premise is that <em>not all</em> j-factors are internal.
<ul>
<li>Externalism isn't as strong.</li>
<li>Internalism has some proofs to do.</li>
</ul></li>
<li>There are two approaches to internal justifiers:
<ol style="list-style-type: decimal">
<li>Mental states</li>
<li>&quot;Directly accessible&quot; to the agent at time of doxastic decision making.</li>
</ol></li>
<li>Ethical theory regularly work within normativity and rules.
<ul>
<li>A wrong action may fail to be within a rule.
<ul>
<li>A right action may be within the rules.</li>
</ul></li>
<li>&quot;we can say that <em>a doxastic attitude toward a proposition</em> is <strong>justified</strong> just in case <em>it conforms to what is permitted by correct epistemic rules</em> and unjustified in case it doesn’t conform to such rules&quot;
<ul>
<li>This is an externalist notion, surely.</li>
<li>&quot;If S's circumstances include the possession of a certain body of evidence relevant to P, then the correct rules may permit S to believe P.&quot;</li>
<li>If S's doxastic attitude toward a proposition P is justified, then it conforms to what is permitted by correct epistemic rules.</li>
<li>If S's doxastic attitude towards a proposition P conforms to what is permitted by correct epistemic rules, then it is justified.</li>
</ul></li>
</ul></li>
<li>What is meant by calling a justificationally relevant fact &quot;internal&quot;?
<ul>
<li>Two approaches:
<ol style="list-style-type: decimal">
<li>An older approach, anything that is <strong>directly accesible</strong> to the subject at the time of decision making.
<ul>
<li>What is included in directly accessible?</li>
<li>Introspection.</li>
<li><em>a priori</em> cognition</li>
</ul></li>
</ol></li>
</ul></li>
<li>A reason that might motivate internalists is that if you restrict what might justify someone to those facts under their cognition, then they can know just from themselves whether or not they are justified.
<ul>
<li>For instance, a cook book needs to be usable!</li>
<li>While this is a nice motivation for studying knowledge, I do not think you should restrict yourself to one view of knowledge or justification because it helps people. What will help people is the correct, coherent view.
<ul>
<li>&quot;directions to which any epistemic agent can <strong>conform</strong>&quot;</li>
</ul></li>
<li>Another approach is the <strong>infallible guidance</strong> approach, that the right rules will infallibly lead a subject to truth.</li>
</ul></li>
</ul>
<h3 id="internalism-and-inferential-rules">Internalism and Inferential Rules</h3>
<blockquote>
<p><strong>(INF)</strong> If agent <em>S</em> has beliefs in propositions <em>K</em>, <em>L</em>, <em>M</em>, <em>N</em> (at time <em>t</em>), and proposition <em>P</em> is logically entailed by the conjunction of <em>K</em>, <em>L</em>, <em>M</em>, <em>N</em>, then <em>S</em> is permitted (at time <em>t</em>) to believe <em>P</em>.</p>
</blockquote>
<ul>
<li>So what about beliefs that <em>S</em> holds but doesn't have access to at time <em>t</em> but still uses to form the belief that <em>P</em>.
<ul>
<li>All the time in science, portions of problems are abstracted and ignored for the sake of being able to get work done.</li>
<li>If challenged, <em>of course</em> the subject believes that portion of the body of evidence supporting <em>P</em>, but the subject doesn't necessarily need that support to form the belief that <em>P</em>.</li>
<li>It's not that it would suffice not to have this proposition, say <em>M</em>, it's just that it's not necessary.</li>
<li>Goldman writes that internalism is vindicated only when all justifiers are internal, which is a definition, but is this type of doxastic attitude or propositional support captured by internal or external?</li>
</ul></li>
<li><strong>(INF*)</strong> adds the condition of the belief being justified, because it's not enough that the belief be a belief.
<ul>
<li>Justification comes from an external source,</li>
</ul></li>
</ul>
<h3 id="questions-1">Questions</h3>
<ol style="list-style-type: decimal">
<li>&quot;we can say that a doxastic attitude toward a proposition is justified just in case it conforms to what is permitted by correct epistemic rules and unjustified in case it doesn’t conform to such rules&quot; This reads like a default application of normativity to epistemology, but then you write, &quot;If S's circumstances include the possession of a certain body of evidence relevant to P, then the correct rules may permit S to believe P.&quot;
<ul>
<li>This uses an account of justification.</li>
<li>I don't understand how body of evidence got into this formulation. I think that evidentialists might like this formulation, but it could just as easily be something like, &quot;If S's circumstances include the possession of a certain belief-forming process relevant to P, then the correct rules may permit S to believe P.&quot;</li>
<li>Is there any reason that you used this language? A neutral application would be, &quot;If S's doxastic attitude towards a proposition P conforms to what is permitted by correct epistemic rules, then it is justified.&quot;</li>
<li>This would allow a normative evaluation of epistemology to remain agnostic about the correct account of justification.</li>
</ul></li>
<li>I noticed that the chapter was devoted largely to the reasons that internalism cannot work, (I think) largely because justification comes in some way from the truth of the proposition, and this is not accessible in any of the right ways. I see that externalism is the rejection of internalism, and so therefore any refutation of internalism makes externalism more compelling, but I still believe that we need independently good and compelling reasons to be an externalist.</li>
<li>Are there any coherent and compelling compatiblist positions about the internalism/externalism debate? From the reading, I understand that many necessary types of justification are best understood as external and that the chapter doesn't think there are no internal factors, but I don't see why one needs to be more prominent than the other. Justification's link to the truth and normative epistemic rules are clearly external factors, but an agent's access and conformity is, very generally, part of a process which ends internally.</li>
</ol>
<h2 id="september-23rd-2013-seminar">September 23rd, 2013 <small>Seminar</small></h2>
<h3 id="organizational">Organizational</h3>
<ul>
<li>Next week we begin the knowledge portion of the course.</li>
<li>This is the longest of the three knowledge chapters.</li>
<li>Two sessions on this chapter.</li>
<li>For chapter 5, the first half of the chapter and 1 extra reading, and that's posted.
<ul>
<li>Nozick.</li>
</ul></li>
</ul>
<h3 id="internalism">Internalism</h3>
<ul>
<li>It's important for internalism that the evidence for a belief be possessed at time of the belief forming, decision making.
<ul>
<li>Goldman is not shooting at a straw man with this restrictive time.</li>
<li>Sometimes counterexamples and debates turn onto a feature of internalism instead of the primary feature.</li>
</ul></li>
<li>Why is process reliablism externalism?
<ul>
<li>What processes? Belief forming processes.
<ul>
<li>This is internal.</li>
</ul></li>
<li>What reliablism? Reliablism to the truth.
<ul>
<li>This is external.</li>
</ul></li>
</ul></li>
</ul>
<h3 id="questions-2">Questions</h3>
<ul>
<li>&quot;Background belief-forming processes&quot;</li>
<li>Standing belief, &quot;dispositional&quot;</li>
</ul>
<blockquote>
<p>If agent S has justified beliefs in propositions K, L, M, N (at time t), and S thinks that proposition P is logically entailed by the conjunction of K, L, M, N, then S is permitted (<strong>at</strong> time t) to believe P.</p>
</blockquote>
<ul>
<li>I think a better rule would be <em>from</em> time <em>t</em> <strong>onward</strong>.
<ul>
<li>I do not think you need the justifying beliefs to be standing, because that would be too strong.</li>
</ul></li>
</ul>
<h3 id="presentation">Presentation</h3>
<ul>
<li>Connee and Feldman give examples for internalism because it's &quot;good&quot; to believe that one persons belief is better justified than another belief.
<ul>
<li>In the example of Bob and Ray, what makes internalism compelling is that Bob went outside and &quot;internalized&quot; the external justification from the newspaper.</li>
<li>This is a bad example because the belief is made good by the fact that there are <em>both</em> internal and external factors.</li>
<li>&quot;Best explained by&quot;</li>
</ul></li>
</ul>
<h4 id="perception">Perception</h4>
<ul>
<li>&quot;He perceives that <em>p</em>.&quot;</li>
<li>&quot;Perceptual experience&quot;, which is something <em>in the head</em> from the eyes, ears.</li>
</ul>
<h2 id="september-30th-2013-chapter-3-part-i-defining-knowledge">September 30th, 2013 <small>Chapter 3, part I, 'Defining Knowledge'</small></h2>
<ul>
<li>'Know' is the eighth most commonly used verb in English.
<ul>
<li>By contrast, 'justified belief' is used much more infrequently.</li>
</ul></li>
<li>We want a good definition of knowledge to solve the problem of <strong>skepticism about knowledge</strong>.
<ul>
<li>The most common reason we want a good definition of knowedlge.</li>
<li>Descartes' evil deceiver.</li>
<li>Are you a brain in a vat?</li>
</ul></li>
</ul>
<h3 id="the-traditional-view-of-knowledge-knowledge-as-jtb">The Traditional View of Knowledge: Knowledge as JTB</h3>
<ul>
<li>K = JTB</li>
</ul>
<h4 id="the-truth-condition">The truth condition</h4>
<ul>
<li>If someone claims to know something, which we later find out to be false, we feel justified in complaining that they didn't know after all.</li>
<li>Sometimes, however, we will say things like, &quot;I just <em>knew</em> it, but it wasn't so.&quot;
<ul>
<li><strong>free indirect speech</strong>: One can speak from the perspective of someone with more limited or false information.</li>
</ul></li>
</ul>
<h4 id="the-belief-condition">The belief condition</h4>
<ul>
<li>Knowledge is a matter of possessing the truth, and the sort of possession involved seems to be psychological.
<ul>
<li>Memory and Radford cases.
<ul>
<li>&quot;Something <em>like</em> belief.&quot;</li>
</ul></li>
</ul></li>
<li>When you say, &quot;I <em>merely</em> believe it.&quot;, you likely really know, but are concealing some information for some reason or another.</li>
</ul>
<h4 id="the-justification-condition">The justification condition</h4>
<ul>
<li>In the <strong>Meno</strong>, the <strong>Gorgias</strong>, the <strong>Theatetus</strong>, and elsewhere, Socrates distinguishes knowledge from right opinion.
<ul>
<li>If you form lucky beliefs, they do not constitute knowledge because they are <em>unjustified</em>.</li>
<li>They are degrees of justification, like chicken-sexers and those with master intuition.</li>
</ul></li>
</ul>
<h3 id="the-gettier-problem">The Gettier problem</h3>
<ul>
<li>Gettier's assumptions:
<ol style="list-style-type: decimal">
<li><strong>Fallibilism about justification</strong>: A belief can be justified even if it is false.</li>
<li><strong>Justification closure</strong>: If you are justified in believing P, P entails Q, and you (competently) deduce Q from P and accept Q as a result of this deduction, then you are justified in believing Q.</li>
</ol></li>
<li>With these two assumptions in place, Gettier gives two cases which he thinks are cases of having JTB while at the same time lacking knowledge.
<ul>
<li>If he's right, the JTB cannot be knowledge because the conditions are insufficient.</li>
</ul></li>
<li>Types of Gettier cases:
<ol style="list-style-type: decimal">
<li>Smith, Jones, and the Job.</li>
<li>Sheep on the Hill</li>
<li>Havit and Nogot</li>
<li>Barn Facade Country</li>
</ol></li>
<li>What could we <em>add</em> to JTB to avoid Gettier?</li>
<li>Some virtues we should look for in an account of knowledge:
<ol style="list-style-type: decimal">
<li>Knowledge should satisfy closure principles under competent deduction.</li>
<li>The account should show why knowledge is valuable, and why it's better than true belief.</li>
<li>The account should enable us to why when someone knows that P, they can appropriate use P as a premix in their reasoning.</li>
<li>The account should enable us to understand how someone could know that P without being justified with absolute certainty that P.</li>
</ol></li>
<li>In addition to justification closure, there is <strong>knowledge closure</strong>: If you know that P, P entails Q, and you (competently) deduce Q from P and accept Q as a result of this deduction, then you know Q.
<ul>
<li>JTB has knowledge closure, but it isn't assured that JTB+X will have knowledge closure.</li>
</ul></li>
<li>Can you deduce from your knowledge that you have hands that you are not a brain in a vat?
<ul>
<li>Having hands entails not being a brain in a vat.</li>
<li>If you make this deduction, does this give you knowledge that you <em>aren't</em> a brain in a vat?</li>
<li>Doesn't this beg the question?</li>
<li>The principle of knowledge closure doesn't say you come to have new knowledge when you make deductions.
<ul>
<li>It just says that you do know the conclusions of those deductions.</li>
<li>What knowledge closure denies is that you can make the deduction but not know the conclusion.</li>
</ul></li>
<li><strong>abominable conjunction</strong>: “I know I have hands, and from this I infer that I’m not a BIV. But I don’t know I’m not a BIV.”</li>
</ul></li>
</ul>
<h3 id="defeasibility">Defeasibility</h3>
<ul>
<li>A quality of Gettier cases is that there is some fact which if the believer learned, would cause them to revise their beliefs.
<ul>
<li>These are called <strong>defeaters</strong>.</li>
<li>There is a defeater for Henry's belief that he sees a barn: that he is in fake barn country.</li>
<li>There is a defeater in Gettier's Smith, Jones, and the Job case too, which is that Jones will not get the job.</li>
<li>But what of <em>defeater defeaters</em>?
<ul>
<li>The Grabit case.</li>
</ul></li>
</ul></li>
</ul>
<h3 id="no-false-assumptions">No False Assumptions</h3>
<ul>
<li>Gettier cases don't always involve reasoning from false premises.</li>
<li><strong>No false assumptions account</strong>: To know is to have justified true belief that one's belief isn't based on a false assumption.
<ul>
<li>What does it means to be <em>based</em> on a false assumption?
<ul>
<li>your belief is based on a false assumption just if were you to learn that the assumption is false then you would be justified in giving your belief.</li>
</ul></li>
<li>This condition satisfies the barn facade case.</li>
<li>The assumption may be that &quot;things are the way they seem to be.&quot;</li>
</ul></li>
</ul>
<h3 id="reliability">Reliability</h3>
<ul>
<li>What disqualifies Gettier cases from being knowledge is to do with the lack of an objective connection between the subject's belief and the truth.</li>
<li><strong>Causal account</strong>: To know is to have justified true belief such that one’s belief is caused by the fact that makes it true.</li>
<li>When you see a sheep on a hill in a normal case, the sheep's being there <em>causes</em> you to see them which <em>causes</em> you to believe that there is a sheep on the hill.
<ul>
<li>In the Gettier cases, however, your belief is caused by the sheep-shaped rock.</li>
</ul></li>
</ul>
<h2 id="september-30th-2013-seminar">September 30th, 2013 <small>Seminar</small></h2>
<h3 id="links">Links</h3>
<ul>
<li><a href="http://bit.ly/1bWomT5">Kornblith</a></li>
<li><a href="http://bit.ly/19Qfpoi">Speaking</a></li>
<li><a href="http://bit.ly/19Q3ZSK">Key terms</a></li>
</ul>
<h3 id="questions-3">Questions</h3>
<ol style="list-style-type: decimal">
<li>Reflective knowledge and appropriate reasoning.
<ul>
<li>Don't use it in your reasoning unless you know it.</li>
<li>There are some circumstances where you cannot use a piece of knowledge.</li>
<li>What's the norm of assertion?
<ul>
<li>When is it appropriate to assert something.</li>
<li>An epistemological perspective.</li>
</ul></li>
</ul></li>
<li>Defeasibility
<ul>
<li>A wrinkle: two uses:
<ol style="list-style-type: decimal">
<li>Justification defeater</li>
<li>Knowledge defeater</li>
</ol></li>
</ul></li>
<li>Strength of conditions
<ul>
<li>Is there a downside of making a knowledge-condition too strong?
<ul>
<li>A condition <em>for</em> knowledge?</li>
<li>If it ruled out many cases, if it's too strong, it rules out cases when it shouldn't rule them out.</li>
<li>A bad analysis requires too much or too little, not getting the right prediction for knowledge.</li>
</ul></li>
<li>The possible solutions that McGrath suggests rules out too many cases where we would like to say that we have knowedlge, but &quot;wouldn't this be harmless?&quot; …
<ul>
<li>We do not need to categorize our propositions to be knowedlge for them to still be useful.</li>
<li>There is something that tis smuggled in here, which you think knowledge has to be something we can act on.</li>
<li>It's standard analytical terms to get sufficient and necessary conditions.</li>
</ul></li>
</ul></li>
</ol>
<h2 id="october-14th-2013-chapter-3-part-ii-defining-knowledge-and-chapter-4-knowledge-and-skepticism">October 14th, 2013 <small>Chapter 3, part II, 'Defining Knowledge' and Chapter 4, 'Knowledge and Skepticism'</small></h2>
<h3 id="questions-4">Questions</h3>
<ol style="list-style-type: decimal">
<li>pg. 30, on safety, &quot;To know that P is to have justified true belief such that if you were to believe that P, P would be true.” This seems dangerously close to begging the question. ‘If you were to believe that P, then P would be true.’ in use will allow me to point to cases where an agent believes a falsehood and say that what’s wrong about the false belief is that the belief is false, and the cases where the agent believes a truth and say the condition is satisfied because the belief is true. How can safety make truth somehow continent on belief?</li>
<li>pg. 30, safety continued. Furthermore, it also seems very close to being equivalent with a Williamson’s thought that knowledge is unanalyzable, because the formulation holds that we form JTBs “somehow” and it means they’re true. Do or can knowledge-firsters subscribe to safety?</li>
<li>pg. 34, on relevant alternatives, &quot;To know that P is to have JTB where one’s evidence rules out all the relevant alternatives to P.” Would “nearby possible worlds” be a good account of what is a relevant alternative? Admittedly, I haven’t read Lewis and I do not know how precise or supported the notion of “nearby” is.</li>
<li>pg. 4, on skeptical arguments, &quot;Unless I know I haven’t spent my life being deceived by an evil genius, I cannot know anything about the world around me (or even about mathematics or logic).” Why does this entail? I cannot see that it does or does not, but for the argument to be compelling.</li>
<li>On skepticism, generally: I may not be able to provide justification for my not being a BIV or having an evil demon, but why does this necessarily affect my other candidates for knowledge? In “high standards contexts”, I’m satisfied in asserting something like, “It’s possible that I’m a BIV, have an evil demon, etc … and Obama is president.” The domain of the knowledge claim I’m making could be restricted to whatever is being appeared to me and true in that regard, and assume that I believe it and have valid justification. Is that too much to give up to skeptics?</li>
</ol>
<h2 id="october-14th-2013-seminar">October 14th, 2013 <small>Seminar</small></h2>
<blockquote>
<p><em>S</em> knows that <em>p</em> if and only if: 1. <em>P</em> is true 2. <em>B</em><sub><em>s</em></sub><em>p</em> 3. <em>B</em><sub><em>s</em></sub><em>p</em> is <strong>caused by</strong> a <strong>generally reliable</strong> belief forming process. 4. There is no relevant alternative situation in which <em>S</em> would have believed <em>p</em> (using the same process)</p>
</blockquote>
<h3 id="relevant-alternatives-constrastivism-and-closure">Relevant Alternatives, Constrastivism, and Closure</h3>
<blockquote>
<p><strong>Relevant alternatives</strong>: You know that <em>p</em> just when you have a JTB that <em>p</em> and your evidences <strong>rules out</strong> all the <strong>relevant</strong> alternatives to <em>p</em>.</p>
</blockquote>
<ul>
<li><strong>Ruling out</strong> (RO):
<ul>
<li>(RO)-<strong>Sensitivity</strong>: Your evidence rules out an alternative if and only if that if that alternative <em>had</em> obtained, you'd have very different evidence.</li>
<li>(RO)-<strong>Safety</strong>: Your evidence rules out an alternative if and only if: you could not easily have had the same evidence while the alternative was the case.</li>
</ul></li>
<li><strong>Relevance</strong>: The relevance of an alternative <em>A</em> depends on the objective probability of <em>A</em>-like events given the kind of environment you're in and the kind of evidence you have.</li>
</ul>
<blockquote>
<p><strong>Knowledge closure</strong>: If you know that <em>p</em>, and <em>p</em> entails <em>q</em>, you know <em>q</em>.</p>
</blockquote>
<ul>
<li>For knowledge closure to hold, every relevant alternative to <em>q</em> must be a relevant alternative to <em>p</em>.
<ul>
<li><em>Relevant</em> must be <strong>intersective</strong>.
<ul>
<li>Blue is <em>intersective</em> because &quot;blue book&quot; breaks down into &quot;is a book&quot; and &quot;is blue.&quot;</li>
<li>Small is not intersective because &quot;small planet&quot; does not break down into &quot;is a planet&quot; and &quot;is small.&quot;</li>
</ul></li>
</ul></li>
</ul>
<blockquote>
<p><strong>Constrastivism</strong>: Knowledge is a three-place relation between a knower, a proposition, and another &quot;contrasting&quot; proposition.</p>
</blockquote>
<ul>
<li>Some important 'degrees' of knowing that <em>p</em> rather than <em>a</em>:
<ol style="list-style-type: decimal">
<li><strong>Certainty</strong>: <em>a</em> includes <strong>all</strong> alternatives to <em>p</em>;</li>
<li><strong>Relevance theorist's knowledge</strong>: <em>a</em> includes <strong>relevant</strong> alternatives to <em>p</em>;</li>
<li><strong>Useful concept</strong>: <em>a</em> includes <strong>some</strong> alternatives to <em>p</em>;</li>
<li><strong>No knowledge</strong>: <em>a</em> includes <strong>no</strong> alternatives to <em>p</em>;</li>
</ol></li>
</ul>
<h2 id="october-21st-2013-chapter-5-contextualism-and-pragmatic-encroachment">October 21st, 2013 <small>Chapter 5, 'Contextualism and Pragmatic Encroachment'</small></h2>
<ul>
<li>A recent development in epistemology is increased attention to ordinary language.
<ul>
<li>Perhaps one of the failings of skepticism is it is not the same sense of &quot;know&quot; that we actually use.</li>
<li>This is the contention of <strong>contextualists</strong>.</li>
</ul></li>
<li>Furthermore, in analyzing the semantics of the word &quot;know&quot;, new questions have arisen about knowledge itself.
<ul>
<li>In particular, <strong>action</strong> and <strong>assertion</strong>.</li>
<li>This discussion is labelled <strong>pragmatic encroachment</strong>.
<ul>
<li>Whichwhether a person can knows can vary on the practical stakes.</li>
</ul></li>
</ul></li>
</ul>
<h3 id="contextualism">Contextualism</h3>
<ul>
<li>Context-sensitivty is familiar.
<ul>
<li>For instance, the first-person pronoun &quot;I&quot; differs from situation to situation.</li>
</ul></li>
<li><strong>Contextualism about knowledge attributes</strong> claims that &quot;knows&quot; is similarly context sensitive.</li>
<li>If these sense of &quot;know that&quot; vary by demandingness, then we can see how &quot;<em>S</em> knows that <em>P</em>&quot; could be true in one context and false in another context.
<ul>
<li>With <em>lax</em> and <em>demanding</em> contexts.</li>
<li>What skepticism and the analysis of knowledge might be up to is <em>shiftiness</em> with the word &quot;know.&quot;</li>
</ul></li>
</ul>
<blockquote>
<p>Compare ‘empty’. If I say that the refrigerator is empty, when it only has ketchup and baking soda in it, usually all will agree, “yes, it’s empty.” However, if you really wanted to be a pest, you could say, “if it’s empty, it doesn’t have anything in it, and ketchup is something ̧ isn’t it? So it’s really not empty, is it?” Here the emptiness-skeptic (if you will) is pressuring you to use ‘empty’ in a strict sense. But it’s hardly some great victory; it’s just playing on the shiftiness of ‘empty’, i.e., its context-sensitivity. Is the skeptic about knowledge doing something similar?</p>
</blockquote>
<ul>
<li>A good analogy are tabletops and flatness, consider the argument:
<ol style="list-style-type: decimal">
<li>All table-tops have some bumps on them.</li>
<li>If something has some bumps on it, it isn't flat.</li>
<li>Therefore, no tabletops are flat.</li>
</ol></li>
<li>This is a <em>diagnosis</em> of skepticism rather than a <em>solution</em> to skepticism.
<ul>
<li>The skeptical &quot;problem&quot; arises simply because we are <em>bewitched by language</em>, to put it in Wittgenstein's way.</li>
</ul></li>
<li>Two clarifications:
<ol style="list-style-type: decimal">
<li>What &quot;knowing is&quot; does not change, what saying &quot;know&quot; <em>means</em> changes.</li>
<li>&quot;Know&quot; is not lexically ambigious like bank or pen.</li>
</ol></li>
<li>The contextualist needs a good story on the <em>implementation</em> of contextualism. There are two approaches:
<ol style="list-style-type: decimal">
<li><strong>Relevant alternatives</strong> approach and</li>
<li><strong>Epistemic standards</strong> approach.</li>
</ol></li>
</ul>
<h4 id="relevant-alternatives-implementation">Relevant alternatives implementation</h4>
<ul>
<li><strong>Relevant Alternatives Implementation</strong>: A claim “<em>S</em> knows that <em>P</em>” is true in a context of speech <em>C</em> iff <em>S</em> can rule out all alternatives to <em>P</em> that <em>C</em> determines as relevant.</li>
</ul>
<h4 id="the-standards-implementation">The standards implementation</h4>
<ul>
<li>The relevant alternatives approach doesn’t set up a <strong>standard of goodness of epistemic position</strong> and declare that one can’t know anything unless one meets that standard for the proposition.</li>
<li><strong>Standards implementation</strong>: A claim “S knows that P” is true in a context of speech C iff S’s belief that P satisfies the epistemic standard determined by C.</li>
</ul>
<h4 id="problems-for-the-contextualist-diagnosis-of-skepticism">Problems for the Contextualist diagnosis of skepticism</h4>
<ul>
<li>We will briefly consider three sorts of objections in what follows:
<ol style="list-style-type: decimal">
<li>The diagnosis <em>concedes too much</em> to the skeptic.</li>
<li>The diagnosis <em>underestimates the resources</em> of the skeptic.</li>
<li>The diagnosis <em>misrepresents a substantial issue</em> as a <em>merely verbal</em> one.</li>
</ol></li>
</ul>
<h5 id="too-concessive-to-the-skeptic">Too concessive to the skeptic?</h5>
<ul>
<li>You <em>do</em> know that you have hands <em>irrespective</em> of standards or context or alternatives.</li>
</ul>
<h5 id="underestimation-of-the-skeptics-resources">Underestimation of the skeptic’s resources?</h5>
<ul>
<li>The skeptic can avoid context-sensitity:
<ol style="list-style-type: decimal">
<li>For any epistemic standard, unless I meet that standard for I am not a victim of an evil genius I don’t meet that standard for anything about the external world. 2. I don’t meet even ordinary low standards for I am not a victim of an evil genius. 3. Therefore, I don’t meet even ordinary low standards for any propositions about the external world, such as I have hands.</li>
</ol></li>
</ul>
<h5 id="misrepresenting-a-substantive-issue-as-verbal">Misrepresenting a substantive issue as verbal</h5>
<h4 id="contextualism-apart-from-skepticism-the-stakes-shifting-cases">Contextualism apart from skepticism: the stakes-shifting cases</h4>
<h3 id="pragmatic-encroachment">Pragmatic Encroachment</h3>
<h4 id="the-case-for-pragmatic-encroachment">The case for Pragmatic Encroachment</h4>
<ul>
<li><strong>Knowledge-Reasons (KR)</strong>:If you know that P, then P is sufficiently warranted to be a reason you have to believe and do other things.</li>
<li><strong>Safe Reasons (final version)</strong>: if P is sufficiently warranted to be a reason you have to do or believe something, then P is sufficiently warranted to justify you in that action or belief.</li>
</ul>
<h3 id="questions-5">Questions</h3>
<ol style="list-style-type: decimal">
<li>Regarding relevant alternatives, &quot;A claim “S knows that P” is true in a context of speech C iff S can rule out all alternatives to P that C determines as relevant.” It does not seem immediately clear to me that all relevant alternatives are conceivable. There could exist a possible world which is a relevant alternative I need to discount on this view that I and my limited brain cannot imagine. Is this a problem for the view?</li>
<li>Regarding the standards implementation, &quot;The relevant alternatives approach doesn’t set up a standard of goodness of epistemic position and declare that one can’t know anything unless one meets that standard for the proposition.” What does goodness refer to in this context? Is it the sense of suitability, aptness, etc? Or is it the sense of virtue?</li>
<li>Regarding safe reasons, &quot;if P is sufficiently warranted to be a reason you have to do or believe something, then P is sufficiently warranted to justify you in that action or belief.” This seems open to a whole slew of counterexamples, specifically cases of useful but ultimately false beliefs. It is practical, but it does not seem necessary on knowledge. Is this formulation okay with attributing knowledge to, say, Ptolemic models?</li>
<li>Regarding Bank Case A and B, is it possible to teem out the ethical issue from the epistemological issue? The ethical issue is regarding whether the person going to the bank is morally obligated given the level of justification. The epistemological issue is whether the person going to the bank actually is or isn’t justified.</li>
</ol>
<h2 id="october-21st-2013-seminar">October 21st, 2013 <small>Seminar</small></h2>
<h3 id="announcements">Announcements</h3>
<ul>
<li>No make-up class on October 28th, 2013.</li>
<li>Paper due November 4th, 2013.</li>
</ul>
<h3 id="presentation-the-bank-argument-a-non-contextualist-explanation">Presentation <small>The Bank Argument: A Non-Contextualist Explanation</small></h3>
<h4 id="bottom-line-up-front">Bottom-line Up-front</h4>
<ul>
<li>Contextualists fail to consider a plausible explanation for the cases, one that does not require an appeal to contextualism.
<ul>
<li>I will argue for this more plausible explanation.</li>
<li>I will not argue that Contextualism is false.
<ul>
<li>I simply hope to take away some motivation for it.</li>
</ul></li>
</ul></li>
</ul>
<h4 id="contextualism-1">Contextualism</h4>
<ul>
<li>'knows that <em>p</em>' varies in its sense across context of speech. Thus, '<em>S</em> knows that <em>p</em>' can have one sense in one context of use and another in another context.</li>
</ul>
<h4 id="the-bank-argument">The Bank Argument</h4>
<ol style="list-style-type: decimal">
<li>In Case A, you speak the truth when you say, &quot;I know it'll be open.&quot;</li>
<li>In Case B, you speak the truth when you say &quot;I don't know it'll be open.&quot;</li>
<li>Your epistemic position is the same across Cases A and B (stipulated).</li>
<li>If (3), then if 'know' had the same sense in the two contexts, then you couldn't speak the truth in both cases in saying what you do.</li>
<li>So, 'know' must have a different sense in the two contexts (i.e. contextualism is true).</li>
</ol>
<blockquote>
<p>The two invariantist objections we considered so far, the loose use objection to Premise 1 and the current objection to Premise 2 are similar in nature. They both maintain that a certain statement can be appropriate to make without being true, and they both try to explain what makes the statement appropriate despite being false. The question is whether their explanations are more plausible than Premises 1 and 2.</p>
</blockquote>
<h4 id="goldman-comments">Goldman comments</h4>
<ul>
<li>People who publish in a good journal or book have thought <em>very closely</em> about the cases they've illustrated.
<ul>
<li>The case is supposed to have <em>only the cases the author wants</em>.</li>
<li>They wouldn't want any other peculiarities to set in.</li>
<li>It would always be possible when you're given a case, say a Gettier one, and someone just says, &quot;He doesn't know&quot; and a philosopher thinks this is a JTB without K.
<ul>
<li>Suppose someone says no, the reason he doesn't know is because <em>there is a gun to his head</em>.</li>
</ul></li>
</ul></li>
<li>On the basis that the agent thinks that certainty is necessary for knowledge.</li>
<li>If we're talking about philosophical investigations about a case, then we want the carefully constructed case that everyone uses and is aware of what ingredients went in and what features came out.</li>
<li>If you add a feature to a case and do not take away any, it is still too specific to be illuminating for what's captured by the more general case.</li>
<li>&quot;How <em>natural</em> would it be to say this in this context.&quot;
<ul>
<li>We're trying to understand the <em>language</em> of knowledge.</li>
<li>Connect up theory of <em>language</em> with theory of <em>knowledge</em>.
<ul>
<li>The meanings, senses, of languages.</li>
<li>Is this a case in which this is a case of <em>f</em> or not a case of <em>f</em>?</li>
</ul></li>
</ul></li>
<li>No one has to explain a case that is inconsistent.</li>
<li>When you make a case, you want it to be a case that non-philosophers can read, understand, appreciate.</li>
<li>Philosophers would deal with how you deal with cases.</li>
</ul>
<h3 id="questions-6">Questions</h3>
<ol style="list-style-type: decimal">
<li>How does an invariantist arrive a non-arbitrary standard for the word &quot;know&quot;? How is one standard better than another?
<ul>
<li>You're noticing that contextualism is usually opposed to invariantism now'a'days as a type of view.</li>
<li>If you <em>don't</em> accept contextualism, you're going to be an invariantist.</li>
<li>The main person responsible is Peter Unger for this distinction.</li>
<li>One of two types of approaches:
<ol style="list-style-type: decimal">
<li>The standard is always the same.</li>
<li>No, the standards <em>could vary</em>.</li>
</ol></li>
<li>&quot;How could this view <em>possibly</em> be endorsed?&quot;</li>
<li>Unger's first book was called <em>Ignorance</em>, where everyone was ignorant because everyone knew nothing.
<ul>
<li>He uses flatness as one of his examples.</li>
<li>There are <em>absolute terms</em>, where the terms are &quot;<em>X</em> is <em>F</em>, that <em>X</em> is as <em>F</em> as <em>F</em> can be.&quot;
<ul>
<li>Know is an <em>absolute term</em>.</li>
<li>This was his way of defending skepticism.</li>
<li>To know is to have absolute certainty.</li>
</ul></li>
</ul></li>
<li>To be honest, Goldman says, contextualism has made people worry that people are uneasy about invariantism.
<ul>
<li>The <em>one unique threshold</em>.</li>
</ul></li>
<li>There a lot of vague words used categorically.</li>
</ul></li>
<li>On pg. 5, standards implementation, relevant alternatives. Do heightened stakes last through time? Could a standard diminish over time?
<ul>
<li>We're studying relation, phenomena <em>F</em>, and we want to see if we have a case of <em>F</em>, to make an attribution of <em>F</em>.
<ul>
<li>There is a difference between what knowledge <em>is</em> and what knowledge <em>attributions</em> are.</li>
<li>&quot;Knowledge relations.&quot; <em>Really knowing</em>, <em>with certainty</em>.</li>
</ul></li>
</ul></li>
</ol>
<h2 id="october-28th-2013-chapter-6-perceptual-justification">October 28th, 2013 <small>Chapter 6, 'Perceptual Justification'</small></h2>
<ul>
<li>Perception is a source of knowledge.
<ul>
<li>You come to know things about your surroundings.</li>
<li>It is hard to see how we could know much about the world around us if we could not perceive how things are.</li>
</ul></li>
<li>Perception is also a source of justified belief.</li>
<li>So far, this is just the obvious, when we ask <em>how</em> percetption provides us with knowledge and justfied belief.</li>
</ul>
<blockquote>
<p>[S]ome of the hardest and most interesting questions in the epistemology of perception concern in the first instance how perception can provide justification.</p>
</blockquote>
<h3 id="preliminaries-on-perceptual-experience">Preliminaries on perceptual experience</h3>
<ul>
<li>Perception, in paradigm cases, involves <strong>perceptual experience</strong>.</li>
<li>When we have experiences, things and their properties seem <strong>present</strong> to the mind in a way they do not in <strong>non-perceptual thought</strong>.</li>
</ul>
<h3 id="can-experiences-justify-beliefs">Can experiences justify beliefs?</h3>
<ul>
<li>The best argument against perception being able to justify beliefs is the <strong>Sellarsian dilemma</strong>, after Wilfrid Sellars.</li>
</ul>
<dl>
<dt>Dilemma</dt>
<dd><p>A dilemma usually takes the following form:</p>
<ol style="list-style-type: decimal">
<li>Either A or B is true.</li>
<li>If A is true, then such and such is true.</li>
<li>If B is true, then such and such is true.</li>
<li>Therefore, such and such is true.</li>
</ol>
<p>2 and 3 are the <strong>horns</strong> of the dilemma.</p>
</dd>
</dl>
<h4 id="the-case-for-answering-no.">The case for answering &quot;No.&quot;</h4>
<dl>
<dt>Sellarsian dillemma</dt>
<dd><ol style="list-style-type: decimal">
<li>Either experiences have propositional content or they do not.</li>
<li>If experiences have propositional content, then they can justify beliefs only if the experiences themselves are justified.</li>
<li>Experiences cannot be justified.</li>
<li>If experiences have propositional content, they cannot justify beliefs. (From 2 and 3)</li>
<li>If experiences lack propositional content, then having them cannot be havint a reason to believe anything.</li>
<li>If in having an experience we do not thereby have a reason to believe anything, then having an experience cannot justify a belief.</li>
<li>So, if experiences lack propositional content, then they cannot justify beliefs. (From 5 and 6)</li>
<li>Therefore, experiences do not justify beliefs.</li>
</ol>
</dd>
<dt>Propositional content</dt>
<dd><p>Beliefs have propositional content, they are beliefs that <em>certain things are the case</em>.</p>
</dd>
<dd><p>The belief that the squirrel is on the railing has the propositional content that <em>the squirrel is on the railing</em>.</p>
</dd>
<dd><p>Desires and intentions have propositional content. When you desire something you always desire that such and such be the case.</p>
</dd>
<dt>Justification-from-Reasons View</dt>
<dd><p>If S is justified in believing that P, this holds in virtue of S’s &gt; having reasons to believe that P.</p>
</dd>
<dd><p>This says that you are justified in believing something this is because you have reason to believe it. This is related to premise 6.</p>
</dd>
<dt>Propositional View of Reasons</dt>
<dd><p>a reason for belief is a piece of information – a claim, a &gt; proposition – and you have a piece of information as a reason only &gt; if you justifiably believe it is true.</p>
</dd>
<dd><p>The propositional view secures premise 5.</p>
</dd>
</dl>
<ul>
<li>Why can't we think of a headache itself as a reason for believing that S has a headache?
<ul>
<li>Propositionalist reply: Reasons must be the sorts of things that we can <em>give</em> in defense of ourselves or others.
<ul>
<li>Giving something in defense requires that it be articulable.</li>
<li>Things like headaches and visual experiences are not articulable.</li>
<li>I can <em>describe</em> these states, but I cannot <em>express</em> them.</li>
</ul></li>
</ul></li>
</ul>
<h4 id="assuming-they-can-how">Assuming they can, how?</h4>
<ul>
<li>There are two categories of how they could. - <strong>Direct justification</strong>
<ul>
<li><strong>Indirect justification</strong></li>
</ul></li>
</ul>
<dl>
<dt>Indirect theories</dt>
<dd><ul>
<li>&quot;The apple looks green to you.&quot; How could that justify you in believing the apple is green?
<ul>
<li>Don't you have to notice it looks green to you and then to believe it is green <em>on that basis</em>.</li>
<li>According to indirect theories, yes.</li>
</ul></li>
<li>There are three problems for indirect theories:
<ol style="list-style-type: decimal">
<li>It is difficult to get to the conclusion that the apple is green if all you have to start with is the justified belief that it looks green to you.
<ul>
<li>This is hardly conclusive.</li>
</ul></li>
<li>You might have justification to believe <em>p</em> but still lack a justified belief in the cases where you don't believe despite propositional justification or believe on grounds of wishful thinking.</li>
<li>Can’t one be wrong about even about how things look, sound, etc. to one? Couldn’t I get my experience wrong despite my best attempts to get it right?</li>
</ol></li>
</ul>
</dd>
<dt>Basing requirement on doxastic justification</dt>
<dd>Your belief that P is justified only if you are justified in &gt; believing P and you believe that P on the basis of the factors &gt; that make you justified in believing P.
</dd>
</dl>
<h3 id="dogmatism">Dogmatism</h3>
<ul>
<li>The simplest direct theory holds that when you have an experience in which something looks, sounds, etc, a certain way to you, this experience alone is enough to justify you in believing it is that way, unless you have some special reason to think otherwise.
<ul>
<li>the experience of a thing’s appearing a certain way to you provides you <strong>immediate <em>prima facie</em> justification</strong> to believe that the thing is that way.</li>
</ul></li>
</ul>
<dl>
<dt>Dogmatism</dt>
<dd><p>Whenever you have an experience in which a thing appears (i.e., &gt; looks, sounds, etc.) a certain way, <em>F</em>, to you, then you thereby &gt; have immediate prima facie justification to believe that it is &gt; <em>F</em>.</p>
</dd>
<dd><p>But this does not account for hallucinations in which nothing is appearing but it looks to you as if it is.</p>
</dd>
<dt>Dogmatism (expanded version)</dt>
<dd><p>Whenever you have an experience as of something being a certain way, &gt; <em>F</em>, to you, then you thereby have immediate prima facie &gt; justification to believe that it is <em>F</em>.</p>
</dd>
<dt>Skeptical assumption</dt>
<dd><p>In order for an experience of its looking to you that <em>P</em> to justify &gt; you in believing that <em>P</em>, you have to be independently justified &gt; in believing that you aren’t a brain in a vat (aren’t dreaming, &gt; etc.)</p>
</dd>
<dd><p>If dogmatism is true, then this assumption is false. All you need is the experience of a thing looking <em>F</em> to be justified in believing it is <em>F</em></p>
</dd>
<dt>Cognitive penetrability objection</dt>
<dd><ul>
<li>Do we “see” different things depending on which theories we accept?
<ul>
<li>If we do, then if we use what we see to justify those theories, aren’t we going in a circle?</li>
<li>For instance, preformationists believed that every human cell contained an embryo. Imagine one of them looked into a microscope and happened to see something that looked a little like an embryo. This person can not be as justified as a non-preformationist who daw the same thing for what it is, but on this view it may be.</li>
</ul></li>
<li>Consider other influences of our cognitive attitudes on our experiences
<ul>
<li>A novice gold prospector wants to find gold and this desire makes him see the dusty nugget in his pan as gold. Is he justified?</li>
</ul></li>
</ul>
</dd>
<dd><p>An experience is cognitively penetrated just in case a cognitive &gt; state of the person penetrates (i.e., causally influences) the &gt; post-attentional processing of sensory input</p>
</dd>
</dl>
<h4 id="the-speckled-hen-objection">The speckled hen objection</h4>
<blockquote>
<p>Imagine seeing two hens, one with 48 speckles and the other 3. Before you count, you won’t be justified in thinking the first has 48-speckles, but you will be justified in thinking the second one has 3 speckles. The problem for dogmatism is that it seems that in some sense 48-speckledness is present in your experience when you look at the first hen, just as 3-speckledness is present in your experience when you look at the second hen. But if it looks 48-speckled to you, then by dogmatism, wouldn’t you be justified in thinking it is? But you aren’t. So we have a problem for dogmatism, the <strong>speckled hen problem</strong>.<sup><a href="#fn1" class="footnoteRef" id="fnref1">1</a></sup></p>
</blockquote>
<h5 id="responses">Responses</h5>
<dl>
<dt>Seemings</dt>
<dd><p>the dogmatist should understand experiences in the relevant sense as &gt; mental states in which it seems to the subject that a thing is F; &gt; only such seemings can justify<sup><a href="#fn2" class="footnoteRef" id="fnref2">2</a></sup>.</p>
</dd>
<dt>Mode of presentation</dt>
<dd><p>the dogmatism might claim <em>that only experiences in which a property &gt; is present</em> in a certain mode or way provide prima facie &gt; justification</p>
</dd>
<dt>Demonstrative</dt>
<dd><p>the dogmatist might severely restrict her dogmatism so that it only &gt; applies to beliefs <em>such as this thing is that way</em> if an object &gt; looks a certain way to you, you are <em>prima facie &gt; immediately &gt; justified only in believing that it is that way</em>.</p>
</dd>
</dl>
<h2 id="october-28th-2013-seminar">October 28th, 2013 <small>Seminar</small></h2>
<h3 id="sellars-argument">Sellars argument</h3>
<h4 id="propositional-content">Propositional content</h4>
<ul>
<li>Not all content is propositional, it can be smaller.
<ul>
<li>Singular terms or concepts could be part of a proposition.</li>
<li>&quot;That iPad that Olivia is using.&quot; &quot;That iPad&quot; is a part.</li>
</ul></li>
<li>The question is whether experiences as a mental state or any state is a propositional attitude.
<ul>
<li>There is at least a subclass of mental states that have propositional content.</li>
</ul></li>
<li>A feeling of pain, on the other hand, may not have propositional content. It's just a feeling or something like that.</li>
<li>So there are two kinds of mental states:
<ol style="list-style-type: decimal">
<li>Phenomenal character, feeling.</li>
<li>Lacks phenomenal character, has propositional content.</li>
</ol></li>
<li>Everybody agrees that having the property of propositional content is something that at least some mental states might have.
<ul>
<li>In particular, perceptual experiences.</li>
</ul></li>
<li>Sellars' way of defending coherentism by saying that <em>only beliefs can justify beliefs</em>.
<ul>
<li>If you say that beliefs are the only thing that can do this, it affects its justificational status. <strong>Justifiers</strong></li>
<li>Which things and kinds of things are justifiers?</li>
<li>Beliefs, justified beliefs, are justifiers.</li>
<li>Perceptual experiences?</li>
<li>Process reliablism confers justificational changes by means of <em>processes</em>.</li>
</ul></li>
<li>If you make an inference from two premises to a conclusion and your inference and its structure are valid, then the fact that it is valid makes it justified. Or at least contributes.
<ul>
<li>Or if it's invalid, then it contributes to its state.</li>
</ul></li>
</ul>
<h4 id="evidentialism-and-internalism">Evidentialism and Internalism</h4>
<ul>
<li>For them, the only things that are justifiers are mental states.</li>
<li>Suppose Jones believes <em>p</em> and that &quot;if <em>p</em> then <em>q</em>&quot;.
<ul>
<li>Is he propositionally justified in believe in <em>q</em>?</li>
<li>You're in a state such that if you were in that state, then it would be justified.</li>
</ul></li>
<li>What are the things that confer the justificational status?
<ul>
<li>It's not only that Jones believes it.</li>
<li>It's also that the argument is <em>valid</em>.
<ul>
<li>This is not a mental state.</li>
</ul></li>
</ul></li>
<li>Would it be plausible that only mental states are justifiers for doxastic?
<ul>
<li>No, because for process reliablists, it's not only the doxastic <em>state</em> but the doxastic <em>process</em>.</li>
</ul></li>
<li>There's a lot of room of play for justifiers.</li>
</ul>
<h4 id="the-premises">The premises</h4>
<blockquote>
<ol style="list-style-type: decimal">
<li>If experiences have propositional content, then they can justify beliefs only if the experiences themselves are justified.</li>
</ol>
</blockquote>
<ul>
<li>If we agree that nothing can be a justifier without itself being justified.</li>
</ul>
<blockquote>
<ol style="list-style-type: decimal">
<li>But experiences cannot be justified<sup><a href="#fn3" class="footnoteRef" id="fnref3">3</a></sup>.</li>
</ol>
</blockquote>
<ul>
<li>This is uncomfortable.</li>
</ul>
<blockquote>
<ol style="list-style-type: decimal">
<li>If experiences lack propositional content, then having them cannot be having a reason to believe anything.</li>
</ol>
</blockquote>
<ul>
<li>This horn is being pursued by <em>having a reason</em>.
<ul>
<li>We have not spoke much about reasons.</li>
<li>It's hard to sum up use of the word &quot;reason.&quot;
<ul>
<li>Mostly until recently mainstream epistemologists have not been using &quot;reason&quot; as a favorite word.</li>
</ul></li>
</ul></li>
</ul>
<h4 id="experience-and-justification">Experience and Justification</h4>
<ul>
<li>If you think that experiences have propositional content, then you might think that the only beliefs that experiences have power over are the same ones. <em>V</em>(<em>G<strong>S<em>) ⇔ </em>B<em>(</em>G</strong>S</em>)</li>
</ul>
<h3 id="dogmatism-1">Dogmatism</h3>
<ul>
<li>If we're going to be accurate about our representation of the world that everything happens from the analysis of the datum from the sense.
<ul>
<li>You get sound waves, shapes, lights, etc.</li>
</ul></li>
<li>How much penetrability happens from high-level beliefs?
<ul>
<li>For present purposes, admit that it can happen <em>some of the time</em>.</li>
<li>What should epistemologists do about this?
<ul>
<li>Theory-ladenness and perception in the 50s and 60s for philosophy of science and Thomas Cuun and Hanson is that what you already believe and already be trained on, say the bird watcher and what they're trained to detect, then the training is in your memory and part of your prior cognition, can this warp your experience?</li>
<li>A lot goes on without your being aware of it.</li>
</ul></li>
<li>For instance, distinguishing twins, sometimes you can determine <em>that <strong>that</strong> is Sally and that <strong>that</strong> is Sandra</em>, but not <em>how</em> or <em>why</em> this is the case.
<ul>
<li>Does the processing make a causal difference in the way that things appear? Top-down, Bottom-up processing.</li>
</ul></li>
</ul></li>
<li>Your fears and emotions and wishes make it so that you &quot;see&quot; people you might want or not want to see.</li>
<li>Dogmatism takes the function of the what the perceptual state is like to be the only determining factor in justification.
<ul>
<li>It's like jumping to a conclusion.</li>
</ul></li>
<li>What if it turns out that observation <em>is not</em> pure and unadulterated?
<ul>
<li>What if people in one laboratory have beliefs that make them observe to fit their theory in a way that contradicts the observations of people in another lab with another theory.
<ul>
<li>If emotions distort beliefs, it could make it observation impossible.</li>
</ul></li>
</ul></li>
</ul>
<blockquote>
<p>Maybe we have lower-level experiences that are not penetrated.</p>
</blockquote>
<ul>
<li>This is something that people in psychology and vision science insofar as perceptual belief, not all belief is perception based, what does it mean to be &quot;directly perception based&quot;?
<ul>
<li>What is this special class and how is it picked out?
<ul>
<li>The intuitive idea with which people start are the elements of the perceptual system.</li>
<li>In the case of vision, there are shapes. Within visual science, people represent things in terms of <a href="http://en.wikipedia.org/wiki/Geon_(psychology)">geons</a>.</li>
</ul></li>
</ul></li>
</ul>
<h2 id="november-4th-2013-seminar">November 4th, 2013 <small>Seminar</small></h2>
<ul>
<li>Theories of justification hold that j-factors, ones which affect another beliefs warrant, what are the justifiers?
<ul>
<li>What are the <em>staes of affairs</em> that influence the status as a belief being satisfied or unsatisfied.</li>
</ul></li>
<li>The problem for reliabalism is to define the process, but everything else is explicit and not obscure.</li>
<li>Maybe foundationalism, the perceptual side for instance, there is some reference to psychological work.
<ul>
<li>So it's not just reliablism.</li>
<li>It would be natural to bring into the picture questions of cognitive size is best positioned to address.
<ul>
<li>There's nothing we really know everything about.</li>
</ul></li>
<li>It looks like addressing the question of &quot;how do we go about achieving justified belief?&quot; is an entree into cognitive science.
<ul>
<li>The meliorative conception, &quot;making better.&quot;</li>
<li>If you want to make better your cognitive or intellectual or belief-forming or evidence-getting, you have to answer this question.</li>
<li>For instance Descartes.</li>
</ul></li>
<li>The rationalist empiricist debate, what is our main capacity to get us to the truth. Some wanted to say <em>reason</em>. Some wanted to say <em>observation</em>.
<ul>
<li>These are claims about how knowledge is acquired.</li>
<li>Hume: &quot;This is the only way to do it.&quot;</li>
<li>So we're not leaving epistemology in doing this.</li>
</ul></li>
<li>It really sounds like a lot of early thinkers are talking about psychology. But there wasn't even such a word.
<ul>
<li>So we're not abandoning the field.</li>
</ul></li>
<li>There are parts which has just lain fallow.</li>
</ul></li>
<li>Meliorism &quot;making better&quot;, well to talk about what we could do better we have to ask &quot;What are we doing now?&quot;
<ul>
<li>Maybe psychology is the way of avoiding glitches.</li>
<li>There general problem is &quot;How should you go about conducting your intellectual affairs?</li>
</ul></li>
<li>Looking at things from a psychological perspective</li>
<li>A big part of epistemology is making normative judgments of justification and warrant.</li>
</ul>
<h2 id="november-11th-2013-chapter-9-philosophys-intuitional-methodology-and-the-role-of-science">November 11th, 2013 <small>Chapter 9, 'Philosophy's Intuitional Methodology and the Role of Science'</small></h2>
<h3 id="the-armchair-or-the-laboratory-where-and-how-to-do-philosophy.">The Armchair or the Laboratory? Where and How to Do Philosophy.</h3>
<ul>
<li>This chapter is concerned with a methodology that cuts across most branch of philosophy.
<ul>
<li>A feature of philosophy that stands out because of disapproval a disuse from the sciences: <em>intuitions</em>.</li>
<li>Empirical evidence is based on <em>observation</em>.
<ul>
<li><em>Truth</em> is obtained by observing the world.</li>
</ul></li>
</ul></li>
<li>Why is philosophy so different? Is this method legitimate?</li>
</ul>
<dl>
<dt>Intuition</dt>
<dd><p>It is a seeming-that-<span class="math">\(p\)</span>-is-the-case which is not based on conscious perception, memory, or inference.</p>
</dd>
<dd><p>It is a sense that <span class="math">\(p\)</span> is the case that wells up in the mind without a readily specifiable reason; it just strikes one (often compellingly) that P is so.</p>
</dd>
<dd><p>In contrast to hunches or guesses, however, intuitions do not feel arbitrary or ill-founded. On the contrary, they &quot;present themselves&quot; as obvious and often routine.</p>
</dd>
</dl>
<blockquote>
<p>But why do we say that philosophers regularly appeal to such seemings? Where and when do they appeal to them?</p>
</blockquote>
<ul>
<li>A principle context is when philosophers try to define or analyze a philosophically interesting term.
<ul>
<li>For instance, <em>knowledge</em> in epistemology.</li>
<li>Alternative, <em>causation</em> and <em>moral rightness</em>.</li>
<li>Definitions typically seek the necessary and sufficient conditions for the use of the term.</li>
<li>For instance, <span class="math">\(JTB \to K \land K \to JTB\)</span>.
<ul>
<li>But the Gettier's counterexample showed that at least one time, <span class="math">\(\lnot K \to JTB\)</span>.</li>
<li><span class="math">\(\lnot K\)</span> was derived from intuition, whereas <span class="math">\(JTB\)</span> was derived from analysis and the case.</li>
<li>All epistemologists, or most, agreed about the intuition, so the definition was shown to be insufficient.</li>
</ul></li>
</ul></li>
</ul>
<blockquote>
<p>Exactly how did the &quot;refutation&quot; take place? Was there some other theory of knowledge epistemologists agreed upon from which they deduced that Smith did not know Q (the job-getter proposition)?</p>
</blockquote>
<ul>
<li>No. There was no alternative theory of that sort.
<ul>
<li>It <em>would</em> be wrong to classify it as knowledge, however.</li>
<li>This is what philosophers call &quot;having a intuition.&quot;</li>
</ul></li>
<li>However, for a theory to be refuted, isn't it required that the person have a <em>bona fide</em> counterexample?
<ul>
<li>How does the Gettier reader form a justified belief that Jones does not have knowledge?
<ul>
<li>Well, apparently, intuition confers this justification.</li>
</ul></li>
<li>This is the role of intuition where <em>intuitions confer justification</em>, <em>intuitions serve as evidence</em>.</li>
</ul></li>
</ul>
<blockquote>
<p>What makes intuitions constitute evidence for their contents? Are they like perceptual experiences, which might serve an analogous role?</p>
</blockquote>
<ul>
<li>Maybe we are really wrong to grant this epistemic role to intuitions.
<ul>
<li>Scientists never use them.</li>
<li>Psychologists dismiss other psychologists that use them.</li>
<li>So why should philosophers be allowed to use them?
<ul>
<li>Maybe philosophers just arrogate to themselves what is in fact a dubious epistemic practice.</li>
<li>This is what philosophers of the last few decades have worried about.</li>
</ul></li>
</ul></li>
<li>Intuitions are clearly not sense experiences
<ul>
<li>They are not part of any empirical method.</li>
<li>Philosophy, as we described it above, is more into thinking up definitions, analyses, and theories and using one's imagination to test them</li>
<li>This &quot;imaginative&quot; testing, often called thought experiments, is in some respects what transpires in science.
<ul>
<li>Philosophers want to test their theories too.</li>
</ul></li>
<li>Philosophers tests traditionally involve no manipulation of worldly subject matter to see how outcomes change.
<ul>
<li>Merely imaginative constructs of possible scenarios.</li>
<li>This can be done from the armchair, and thus constitutes an <strong>armchair discipline</strong>.</li>
<li>Notice that mathematics may also be characterized as such.</li>
</ul></li>
</ul></li>
</ul>
<h3 id="rationalism-vs.-empiricism">Rationalism vs. Empiricism</h3>
<ul>
<li>This entire issue harks back to an extremely important debate in the history of epistemology between <em>empiricism</em> and <em>rationalism</em>.
<ul>
<li>The debate is framed between three rationalists:
<ol style="list-style-type: decimal">
<li>Descartes</li>
<li>Spinoza</li>
<li>and Leibniz</li>
</ol></li>
<li>And three empiricists:
<ol style="list-style-type: decimal">
<li>Locke</li>
<li>Berkeley</li>
<li>and Hume</li>
</ol></li>
</ul></li>
</ul>
<dl>
<dt>Rationalism</dt>
<dd><p>emphasizes the role of <em>reason</em> in knowledge</p>
</dd>
<dd><p>paradigmatic cases include mathematical thought, logical thought, and other kinds of abstract thinking that feature purely abstract contents rather than sensory, or sense-derived concepts.</p>
</dd>
<dt>Empiricism</dt>
<dd><p>emphasizes the role of <em>sense-experience</em> in knowledge</p>
</dd>
<dd><p>highlighted the centrality of sense-based cognition and rationalists the centrality of abstract modes of cognition.</p>
</dd>
<dd><p>Gained fairly clear ascendance in the early 20th century, because of the association between science and empiricism and the success of science</p>
</dd>
<dd><p>The rise of logical positivism berated the standing of rationalist notions of &quot;rational insight&quot; and &quot;intuitive insight&quot; and the like.</p>
</dd>
</dl>
<blockquote>
<p>... [T]he truths of pure reason, the propositions which we know to be valid independently of all experience, are so only in virtue of their lack of factual content. <cite>(A.J. Ayer, 1952. Language, Truth, and Logic. New York: Dover, pp. 93-94)</cite></p>
</blockquote>
<ul>
<li>Ayer did not wholly reject non-empirical knowledge.
<ul>
<li>Relegated it to a lesser domain.</li>
</ul></li>
</ul>
<blockquote>
<p>Can we show that reliance on intuition in philosophical methodology has a firm epistemological ground?</p>
</blockquote>
<h3 id="kinds-of-intuition-and-the-nature-of-intuition">Kinds of Intuition and the Nature of Intuition</h3>
<ul>
<li>Presumably, intuitional states are propositional attitudes, which imply the state has two parts:
<ol style="list-style-type: decimal">
<li>An attitude type</li>
<li>Propositional content</li>
</ol></li>
</ul>
<blockquote>
<p>Are logical and mathematical intuitions the same kind of mental states as moral intuitions? Type or content?</p>
</blockquote>
<h3 id="a-criterion-of-evidencehood">A Criterion of Evidencehood</h3>
<ul>
<li>The author proposes <em>reliabilist evidencehood</em>, specifically <em>indicator reliablism</em>.</li>
</ul>
<blockquote>
<p>The occurrence of an event or state of affairs of type <span class="math">\(\Sigma\)</span> is counted as evidence for proposition <span class="math">\(p\)</span> if <span class="math">\(\Sigma\)</span> is a generally reliable indicator of the truth of <span class="math">\(p\)</span>.</p>
</blockquote>
<ul>
<li>For example, the fact that S seems to remember eating a croissant for breakfast is evidence that he did eat a croissant for breakfast.
<ul>
<li>Analogously, why shouldn't it be plausible that someone's having an intuition that Gettier's coin-in-the-pocket example is not a case of knowledge (on the part of Smith) should also be evidence?</li>
</ul></li>
</ul>
<blockquote>
<p><strong>(IND-EV)</strong> If being in a propositional attitude of type <span class="math">\(M\)</span> is a generally reliable indicator<sup><a href="#fn4" class="footnoteRef" id="fnref4">4</a></sup> of the truth of <span class="math">\(M\)</span>'s content, then if <span class="math">\(S\)</span> is in a token state of type <span class="math">\(M\)</span> with respect to proposition <span class="math">\(P\)</span>, this is evidence of the truth of <span class="math">\(P\)</span>. It is evidence for <span class="math">\(S\)</span> of the truth of <span class="math">\(P\)</span>, and if another person <span class="math">\(S\)</span>' is justified in believing that <span class="math">\(S\)</span> is in this state, then <span class="math">\(S\)</span>'s being in a token state of type <span class="math">\(M\)</span> is also evidence for <span class="math">\(S\)</span>' of the truth of <span class="math">\(P\)</span>.<sup><a href="#fn5" class="footnoteRef" id="fnref5">5</a></sup></p>
</blockquote>
<h3 id="philosophical-intuitions-as-classification-judgements">Philosophical Intuitions as Classification Judgements</h3>
<ul>
<li>A pervasive part of cognitive activity is:
<ul>
<li><strong>(A)</strong> forming representations of <em>categories</em>.
<ul>
<li>Ex: dogs, books, red things, explosions</li>
</ul></li>
<li><strong>(B)</strong> <em>classifying</em> or <em>categorizing</em> <em>objects</em> or <em>events</em>
<ul>
<li>Ex: Is this animal a book or dog?</li>
</ul></li>
<li>Spontaneous answers to classifications of knowledge are intuitions.</li>
</ul></li>
<li>If intuitions are <em>reliable indicators</em> of the truth of their contents, then they qualify as a non-empirical type of evidence.
<ul>
<li>We can find this out with experimental philosophy, Goldman claims.</li>
</ul></li>
</ul>
<h3 id="applying-the-experimental-method-to-the-reliability-question">Applying the Experimental Method to the Reliability Question</h3>
<ul>
<li>If a pool of participants in a dichotomous (yes-no) survey question splits their responses 60% to 40%, we can infer that at least 40% of the respondents were giving wrong answers, and therefore have wrong intuitions.<sup><a href="#fn6" class="footnoteRef" id="fnref6">6</a></sup></li>
<li>The results of X-Phi diverged from near unanimity from philosophers with regards to Gettier.
<ul>
<li>A 74% majority of subjects with Western ethnic origins responded that Smith in one of the &quot;only believes&quot; the proposition rather than &quot;really knows&quot; it.
<ul>
<li>East Asian and Indian subjects thought Smith knew.</li>
</ul></li>
</ul></li>
<li>This undercuts the prospect of intuitions being reliable indicators of the truth.</li>
<li>The results have been undercut by lack of replication.</li>
<li>Also do these results equate to intuitions? Maybe not.</li>
<li>Also maybe these subjects do not have the relevant or necessary tools to sufficiently analyze the cases.</li>
<li><em>Properly conducted</em> scientific methodology is very relevant to philosophy.
<ul>
<li>The remedy is <em>better science</em>.</li>
</ul></li>
</ul>
<h3 id="a-more-refined-model-of-classification-reliability">A More Refined Model of Classification Reliability</h3>
<blockquote>
<p><strong>(C-J RELIABILITY)</strong>: The general process of classification judgment has high conditional reliability if and only if it outputs a high ratio of true classification judgments whenever both the case representation and the category representation are accurate.</p>
</blockquote>
<h3 id="possible-targets-of-philosophical-theorizing-and-the-method-of-philosophical-analysis">Possible Targets of Philosophical Theorizing and the Method of Philosophical Analysis</h3>
<ul>
<li>A traditional aim of analytic philosophy is to analyze, define, or give an account of philosophically interesting targets.
<ul>
<li>According to the free-floater approach, philosophy should not concern itself with mere word meanings.
<ul>
<li>It should concern itself with the <em>content</em> of words.</li>
</ul></li>
</ul></li>
<li>The notion of &quot;direct acquaintance&quot; is appealing to rationalists.</li>
</ul>
<h2 id="november-11th-2013-seminar">November 11th, 2013 <small>Seminar</small></h2>
<h3 id="questions-7">Questions</h3>
<h4 id="on-meliorative-epistemology">On Meliorative Epistemology</h4>
<ul>
<li>There is no consensus on the thesis of meliorative epistemology.
<ul>
<li>The people that have used it most are not mainstream, and if different people have used it, they maybe haven't defined it.</li>
<li>Others topics will be much more well defined.</li>
</ul></li>
<li>Nonetheless, there is a lot of precedent for it.
<ul>
<li>Descartes, for example, has a book called <a href="http://en.wikipedia.org/wiki/Rules_for_the_Direction_of_the_Mind"><em>Rules for the Direction of the Mind</em></a>.</li>
<li>&quot;Here are rules for how to do things right.&quot;</li>
<li>Regulative vs. Meliorative.</li>
</ul></li>
<li>A lot of X-Phi is aimed at this regulative/ameliorative approach.
<ul>
<li>Ameliorative epistemology is both descriptive and normative.</li>
<li>Mainstream epistemology are not &quot;in this business.&quot;</li>
<li>Sometimes there is the presupposition that &quot;what we do is good.&quot;</li>
<li>Psychologists have a conception of what we <em>should</em> be doing as well, from heuristics and biases.</li>
</ul></li>
<li>If you expect there to be one consensus view on what to say here, you will disappointed.</li>
<li>Things are not that neat.
<ul>
<li>In general, though not about all four chapters, there's a lot less consensus about how things should be done.</li>
</ul></li>
</ul>
<h4 id="on-rationality-normativity-and-description">On Rationality, Normativity, and Description</h4>
<blockquote>
<p>Does melioristic epistemology affect our definition of knowledge? One of the projects of epistemology is to define knowledge, does melioristic epistemology affect our definitions?</p>
</blockquote>
<ul>
<li>Here's how some of the discourse has gone, the debates on these issues:
<ul>
<li>Going back 25 years at least, after the first main papers on Kahneman and Frisky on heuristics and biases, there was an article by an Oxford philosopher on Cohen, in <em>Behavioral and Brain Sciences</em>, BBS
<ul>
<li>An interdisciplinary journal from a whole lot of people from different schools.</li>
<li>A necessary condition of publishing a target article is of it being of interest to more than one discipline.</li>
<li>It's got to be a kind of paper on a topic that will illicit reactions from different disciplines.</li>
<li>30 responses to target articles.</li>
</ul></li>
<li>Cohen's article was in the 70s, a while back, was something like, &quot;Can Human Irrationality be Proved?&quot;
<ul>
<li>&quot;There's no way psychologists can come along and <em>prove irrationality</em>, because <em>there is no alternative standard</em>&quot;</li>
<li>Empirical psychology cannot make comments on the normative standard, to be rational is what we're capable of doing. &quot;By what we do.&quot;</li>
</ul></li>
<li>Now, the psychologists wanted no proof <em>a priori</em> of our rationality. This was taken for granted by a lot of philosophers.
<ul>
<li>They assume that logic and probability calculus tell us what it is to be rational.</li>
<li>It is to be given by the formal system.</li>
<li>Which is a line that people that work in the sciences assume that these probability.</li>
<li>People like Stanovich, Canadian, in Toronto.</li>
</ul></li>
</ul></li>
<li>Stanovich clearly puts the option on the table, the idea that, you cannot specify what is rational or irrational, you've got to take into account the limits and capacities, to define these, you have to define rationality in terms of these capacities.
<ul>
<li>Well, what are its design capacities, what would it be rational for <em>that</em> kind of agent to do with its resources.
<ul>
<li>This is not how philosophers generally proceed.</li>
</ul></li>
<li>The usual thing to do is, &quot;What does logic, probability, statistics tell us we should do or pick?&quot;</li>
</ul></li>
<li>If you're talking about good and bad ways of reasoning and thinking, even though it isn't <em>morally bad</em>, but it is &quot;derogation of the activity&quot;, well, if you ought, you can. Ought implies can.
<ul>
<li>&quot;Only if something is within your capacity.&quot;</li>
<li>&quot;If we want to talk about what you <em>should</em> do, we need to know about what you <em>can</em> do.&quot;</li>
<li>What would be good to do? It must be something doable.</li>
</ul></li>
</ul>
<h4 id="the-problem-posed-by-empirical-results">The Problem Posed by Empirical Results</h4>
<blockquote>
<p>Why are we supposed to be that worried? You say stuff like, &quot;Can psychology come to the rescue showing us that we can be the rational creatures we have ourselves being?&quot;</p>
</blockquote>
<ul>
<li>There are several things here, and you can pick one of them
<ul>
<li>But first of all, this presupposes there have been one or more serious challenges.</li>
<li>Certain people that I (Alvin Goldman) talk about, judgment and decision making, but the heuristic and biases approach, people think that in a fundamental sense, people are irrational.</li>
<li>This is just a &quot;little sampling.&quot;</li>
</ul></li>
</ul>
<blockquote>
<p>To even do this kind of research is to assume that we know what rational is.</p>
</blockquote>
<ul>
<li>Naive people, where naive is not having special training in the field.
<ul>
<li>I'm not sure there is one line about what system 2 is.</li>
<li>But, to get back to main theme, they are interested in saying &quot;How do people, without any special tutoring or training, what are our native capacities?&quot;
<ul>
<li>Naive is not insulting, just descriptive.</li>
</ul></li>
<li>How do we, say, &quot;read the minds of others.&quot;
<ul>
<li>To have &quot;trouble&quot; understanding other people.</li>
<li>Nobody has to go to school to read others minds. Babies start doing it very early<sup><a href="#fn7" class="footnoteRef" id="fnref7">7</a></sup>.</li>
<li>It's the naive ability to do that we're interested in.</li>
</ul></li>
</ul></li>
</ul>
<blockquote>
<p>Why should I care <em>as an epistemologist</em>? Is this a skeptical challenge? Maybe just because I never thought we were that great at knowledge with our naive abilities.</p>
</blockquote>
<ul>
<li>Here's response I was presupposing.
<ul>
<li>Mainstream epistemologists think that the skeptical thesis is that we do not know nearly as much knowledge as we think we do.
<ul>
<li>Not necessarily that we have no knowledge.</li>
<li>It's even a skeptical thesis that we have fewer justified beliefs than we think we do.</li>
</ul></li>
<li>Well, we believe a lot in bad ways. So we're not justified and we do not know.</li>
<li>Who is the we?
<ul>
<li>&quot;The ordinary person in the street.&quot;</li>
<li>Philosophers of science are interested in scientists.</li>
</ul></li>
<li>The underlying theme of mainstream epistemology is something like what I'm talking about now, naive cognition, rather than sophisticated, trained belief.</li>
</ul></li>
</ul>
<h4 id="one-kind-of-example-the-availability-heuristic">One Kind of Example <small>The Availability Heuristic</small></h4>
<blockquote>
<p>Which has a higher frequency? Words that end in &quot;ing&quot; or words that have &quot;n&quot; in the second to last position?</p>
</blockquote>
<ul>
<li>There is both the mistake, and what leads to the the mistake.</li>
<li>They dub the availability heuristic as what is happening here, where we're using memory to answer questions a zillion times a minute.
<ul>
<li>It's easier to recall from memory cases of &quot;ing&quot; that cases of &quot;n&quot; in the second to last position.</li>
<li>It's hard because we do not mentally classify words based on there second to last letter.
<ul>
<li>We do, alternatively, store words with syllables, or at least more so.</li>
</ul></li>
</ul></li>
<li>There is a kind of bias in this kind of thinking, because a lot of tasks happen using your memory, and so if there are flaws, or if we do it a lot, we can generate zillions of such examples of what gets retrieved from memory and how.
<ul>
<li>It &quot;silently shapes&quot; how we see things.</li>
<li>What's available for retrievably is not well ordered to truth.</li>
<li>We have things that systematically take us in the wrong direction.</li>
</ul></li>
<li>You're asked a probability question, where Linda is given a description, and you rank whether she is a bank-teller or feminist, etc, but in related experiments, if people are asked how representative of a bank-teller Linda is, people give roughly the same answer in answering that question for how representative she is, the same answer as the probability question.
<ul>
<li>Maybe people are substituting that question. They are ranking in representative similarity.</li>
<li>The tendency to substitute one question for another.</li>
<li>The whole tendency of this group of psychologists is to emphasize what we do incorrectly<sup><a href="#fn8" class="footnoteRef" id="fnref8">8</a></sup>.</li>
</ul></li>
</ul>
<h3 id="presentation-1">Presentation</h3>
<h4 id="some-preliminary-remarks">Some Preliminary Remarks</h4>
<ul>
<li>Validity: Necessarily, if the set of premises in are argument all true, then the conclusion cannot be false.</li>
<li>If we take ourselves to have intrinsic abilities to deductively reason, then having a grasp on validity should be thought of as a necessary condition for being a skilled deductive reasoner.
<ul>
<li>Lets accept the view that we posses native deductive reasoning abilities and call it the optimistic view (Goldman 1986)</li>
<li>But note that it isn't always a good strategy to mindlessly add all logical entailments into your belief set.</li>
</ul></li>
</ul>
<h4 id="belief-bias">Belief Bias</h4>
<ul>
<li>Whether or not conclusion is believably influences how we judge the argument's validity.</li>
<li>Makovits and Nantel (1989) tested the following syllogism on university students:
<ol style="list-style-type: decimal">
<li>All living things need water.</li>
<li>Roses need water.</li>
<li>Roses are living things.</li>
</ol></li>
<li>Logical form:
<ol style="list-style-type: decimal">
<li><span class="math">\(\forall(Lx \to Wx)\)</span></li>
<li><span class="math">\(Wr\)</span></li>
<li><span class="math">\(Lr\)</span></li>
</ol></li>
<li>70 percent of the subject population deemed the dressed up argument as valid, while its logical form is clearly invalid.</li>
<li>This lends well to the mental model theory of the psychology of deductive reasoning, while seemingly undercutting the mental logic theory.</li>
</ul>
<blockquote>
<p><strong>(Mental Logic Theory)</strong>: We posses some internal logical deduction schemata and rules, analogous to an internalized natural deduction model.</p>
<p><strong>(Mental Model Theory)</strong>: We construct an inner semantics for the arguments premises which we then manipulate to asses validity.</p>
</blockquote>
<ul>
<li>With regards to the rose argument, it seems much clearer to see how one could go wrong in the mental model theory, sine once could construct an inadequate model. However, if we have an internalized version of logical schemata and rules, the it seems as if subjects should see the argument's invalidity since there is no valid inference to get from P1 and P2 to C.</li>
<li>One plausible explanation (from Stanovich 2004) is that we have this innate tendency to take into account all of the contextual information when attempting to solve a problem.</li>
<li>Compare the above with Johnson Laird (1983):</li>
</ul>
<blockquote>
<p>The heart of the process is interpreting premises as mental models that take <em>general knowledge</em> into account, and searching for counterexamples to conclusions by constructing alternative models of the premises.</p>
</blockquote>
<ul>
<li>Object to Mental Model Theory: Although we make up the inference rules in MMT, they still have properties of logical syntax. So, manipulating mental models is not different than manipulating mental propositions. Thus, we already have inference rules in order to operate on the models and these rule are those predicted by the MLT.</li>
</ul>
<h4 id="content-bias">Content bias</h4>
<ul>
<li><p>Wason card selection task conditional: If a card has a bowl on it, then it has en even number on the other side:</p>
<pre><code>+---+  +---+  +---+  +---+  
| A |  | D |  | 4 |  | 7 |  
+---+  +---+  +---+  +---+  </code></pre></li>
<li>How does one falsify the conditional? By flipping the A and the 7. However, most subjects (46%) chose A with the 4 instead.
<ul>
<li>Only 4% of Wason's subjects correctly answered A,7.</li>
</ul></li>
<li>Yet, when given the following task, subjects performed far better.
<ul>
<li><p>Conditional: If drinking beer, then subject is over 19.</p>
<pre><code>+------+  +------+  +------+  +------+  
| Beer |  | Soda |  |  25  |  |  17  |  
+------+  +------+  +------+  +------+  </code></pre></li>
</ul></li>
<li>73% of subjects correctly answered that one should turn over the &quot;beer&quot; and &quot;17&quot; cards (Grigs and Cox 1982)</li>
<li><p>The different in the results between the abstract vowels/even number selection task and the beer/age selection task can be understood through the content bias, namely the basis we have towards familiar contents.</p></li>
</ul>
<h4 id="two-explanations">Two Explanations</h4>
<blockquote>
<p><strong>(Permission Schema)</strong>: If a person satisfies condition <span class="math">\(A\)</span>, then that person gets to carry out actions <span class="math">\(B\)</span>.</p>
</blockquote>
<!-- -->

<blockquote>
<p><strong>(Social Exchange Theory)</strong>: We have adapted certain intuitions regarding the trade off of goods.</p>
</blockquote>
<h3 id="lesley-induction-and-philosophy-of-science">Lesley, Induction, and Philosophy of Science</h3>
<ul>
<li>There's good reason to thnk that lots of animals have a built-in mechanism to induce from experience.
<ul>
<li>The epistemological problems about the justification of induction, and then the empirical questions of the general picture of the mind and its cognitive capacities, well, that's interesting.</li>
<li>In general, the topic of induction is talked about not specific in this respect is applied to thought, not necessarily language.</li>
</ul></li>
<li>Lesley is working on the problem of generics.
<ul>
<li>Generics is something that is investigated by linguists.</li>
<li>More recently by psychologists.</li>
<li>Generics are not universals or existential.</li>
</ul></li>
<li>Generics:
<ul>
<li>Tigers growl.</li>
<li>Fish swim.</li>
</ul></li>
<li>Pointing is important to humans ability to learn.
<ul>
<li>Giving content to utterances.</li>
<li>Similarly, following the gaze of what people look at.</li>
</ul></li>
<li>&quot;Mosquitoes carry the West Nile virus.&quot;
<ul>
<li>Only 1% of these creatures do this.</li>
</ul></li>
<li>&quot;Cats are female.&quot;
<ul>
<li>Only 50% of cats are female.</li>
</ul></li>
<li>Useful ways of generalizing.
<ul>
<li>You can decide that they are true on evidence that is well shy of investigation of many cases.</li>
</ul></li>
<li>Life is such that you want to be able to act quickly and you can make judgments quickly.</li>
<li>There is difference between what it takes to accept a generic and your tendency to assume of some member of that group has that property.</li>
</ul>
<h2 id="november-18th-2013-philosophical-naturalism-and-intuitional-methodology-by-alvin-i.-goldman">November 18th, 2013 <small>Philosophical Naturalism and Intuitional Methodology <em>by Alvin I. Goldman</em></small></h2>
<h3 id="intuitions-in-philosophy-whats-the-controversy">Intuitions in Philosophy: What’s the Controversy?</h3>
<ul>
<li>A debate is raging over philosophical method.
<ul>
<li>There are <em>traditionalists</em> and <em>naturalists</em>.
<ul>
<li>Naturalists are distinct in that they are science oriented towards intuitions in philosophy.</li>
</ul></li>
<li>Not everyone likes the term &quot;intuition,&quot; but it is the most common term.</li>
</ul></li>
</ul>
<dl>
<dt>Intuition</dt>
<dd><p>The philosophical activity in question consists of specifying a hypothetical scenario and rendering an intuitive judgment about the correctness or incorrectness of classifying it under a stipulated heading.</p>
</dd>
<dd><p>Does a given predicate ‘F’ apply to an event, an individual, a pair of objects, etc. in the scenario? Putting the question less linguistically, is a certain property or relation exemplified in the scenario?</p>
</dd>
</dl>
<ul>
<li>Intuitions in philosophy are important because, for example, Gettier debunked the entire JTB analysis of knowledge with nothing but an intuition.</li>
<li>Consulting intuitions about imaginary cases is paradigmatic of &quot;armchair philosophy.&quot;
<ul>
<li>Philosophical naturalists use &quot;real empirical experimentation.&quot;</li>
<li>Philosophy should not be dragged into epistemological disrepute by utilizing suspect faculties like intuition.</li>
</ul></li>
<li>The debate has intensified with X-Phi.
<ul>
<li>Stephen Stich, a proponent of the &quot;negative&quot; variety, claim their experimental studies raise skeptical doubts about the epistemic soundness or robustness of philosophical intuition.</li>
<li>Although X-Phi doesn't speak for all of philosophy, they do raise questions about the epistemic credentials of intuitions.</li>
<li>They challenge the evidential status that the bulk of the profession routinely accords with.</li>
</ul></li>
</ul>
<h3 id="two-types-of-evidential-questions-first-order-and-second-order-questions">Two Types of Evidential Questions: First-order and Second-order Questions</h3>
<ul>
<li>The debate over intuitional methodology is customarily formulated in terms of &quot;evidence&quot; and &quot;evidential quality.&quot;</li>
</ul>
<dl>
<dt>Intuitions</dt>
<dd><p>Occurrent mental states, either intuitive judgments (a species of doxastic states) or non-doxastic states such as intellectual &quot;seemings&quot; or &quot;attractions,&quot; which tend to generate intuitive judgments.</p>
</dd>
<dt>First-order questions of evidence</dt>
<dd><p>Are intuitions, or intuitive judgments, evidence at all?</p>
</dd>
<dd><p>What is their evidential quality or strength?</p>
</dd>
<dd><p>For what propositions or hypotheses are they good evidence?</p>
</dd>
<dd><p>For whom are they good evidence (their subjects only, or other &gt; people as well)?</p>
</dd>
<dd><p>What kind of evidence do intuitions have or confer: empirical &gt; evidence or a priori evidence?</p>
</dd>
<dt>Second-order questions of evidence</dt>
<dd><p>Is there evidence (good evidence?) for the first-order evidential &gt; status of intuitions?</p>
</dd>
<dd><p>If we don’t already have good enough evidence for the first-order &gt; evidential status of intuitions, how should we go about gathering &gt; evidence about the first-order status of intuitions?</p>
</dd>
<dd><p>What are the most appropriate or most helpful kinds of second-order &gt; evidence: empirical or a priori?</p>
</dd>
</dl>
<ul>
<li>The work advances the view that the two orders of status for intuitions are of different types.
<ul>
<li><em>Intutions may have first-order evidential status of a substantially a priori kind</em>.</li>
<li>While their second-order evidential status, the evidence for their evidential status, is mainly an <em>empirical</em> kind.</li>
<li>Goldman does not firmly endorse the bifurcated view.</li>
</ul></li>
</ul>
<h3 id="the-nature-of-evidential-states">The Nature of Evidential States</h3>
<blockquote>
<p>What is evidence? That is, what kinds of evidence of states-of-affairs constitutes pieces of evidence, and in virtue of what relation to an appropriate relatum do they so qualify?</p>
</blockquote>
<ul>
<li>Kelly (2008) distinguishes between several senses of evidence.
<ul>
<li>There is the &quot;reliable indicator&quot; sense of evidence, in which some thing is evidence for another just in case that first thing is a fairly reliable sign, or indicator, of the truth or existence of that second thing.</li>
<li>When using the reliable indicator sense of &quot;evidence&quot;, we should use the <em>state-of-affairs</em> or <em>factive</em> entities that constitute evidence.
<ul>
<li>For example, there being 743 rings on the trunk of a given tree is good evidence for the proposition that the tree is 743 years old.</li>
</ul></li>
</ul></li>
</ul>
<blockquote>
<p>Can a mental state qualify as good evidence under the proposed sense of evidence?</p>
</blockquote>
<ul>
<li>Certainly, if we tweak the proposal to read that <em>somebody's being in a certain mental state</em> is the item of evidence.</li>
<li>Not all mental states with contents, however, are reliable indicators of the truth of their contents.
<ul>
<li>Wish, imagining, fearing, and so forth, that <span class="math">\(p\)</span>, may not be reliable indicates of the truth of their contents.</li>
<li>Perhaps intuiting that <span class="math">\(p\)</span> is a reliable indicator for a suitably delimited class of intuitings.</li>
</ul></li>
<li>When a philosopher judges that a character in a Gettier case fails know a proposition, the item of evidence isn't the philosopher's intuitive judgement, it is the truth of the proposition so judged, namely, that the character does not know.
<ul>
<li>Williamson contends that the psychological view:
<ol style="list-style-type: decimal">
<li>Misdescribes philosophical practice,</li>
<li>Rests on a false principle about evidence</li>
<li>Opens up an epistemologically unfortunate gap between the thought-expermimental evidence and what it is supposed to be evidence for.</li>
</ol></li>
</ul></li>
<li>There is no room to respond to these worries in detail, but none of them provide well-founded reason to reject a psychological approach to intuitional evidence.</li>
</ul>
<h3 id="indicator-reliability-and-process-reliability">Indicator Reliability and Process Reliability</h3>
<ul>
<li>Interesting case: there was an &quot;ACE-V&quot; method of fingerprint running to match prints, which the FBI used, including the best laboratories.
<ul>
<li>Upon investigating and statistical analysis, there was not second-order evidence to suggest the evidence found with ACE-V was any good at all.</li>
</ul></li>
<li>This illustrates that was is <em>taken</em> as evidence does not confer <em>genuine</em> evidencehood, or at least not <em>good evidencehood</em>.
<ul>
<li>Just as the legal system should surely demand good second-order evidence about the reliability of courtroom forensic testimony, it is reasonable for philosopher to seek analogous tests to obtain second-order evidence about the evidential quality of philosophical methods<sup><a href="#fn9" class="footnoteRef" id="fnref9">9</a></sup></li>
</ul></li>
</ul>
<h3 id="the-negative-program-of-experimental-philosophy">The Negative Program of Experimental Philosophy</h3>
<blockquote>
<p>Exactly what experimental evidence challenges the reliability of intuitions, specifically, singular classification intuitions?</p>
</blockquote>
<ul>
<li>Singular classification intuitions are intuitive judgments that arise when a person is aced whether a certain example is an instance of a specific property or relation.
<ul>
<li>The interesting ones are knowledge, causation, and reference.</li>
<li>X-Phi practitioners of all strings use survey method to compare and contrast intuitions of groups of respondents.</li>
</ul></li>
</ul>
<dl>
<dt>Positive program</dt>
<dd><p>Draw various kinds of inferences from differnces in responses, but they don't fundamentally challenge the epistemologically soundness of intuition-based method.</p>
</dd>
<dd><p>We certainly do not take ourselves to have offered anything like a &gt; general proof of the unreliability of all intuitions... (Alexander &gt; and Weinberg 2008: 153)</p>
</dd>
<dt>Negative Program</dt>
<dd><p>Try to find evidence that raises doubts about the quality go intuition evidence.</p>
</dd>
</dl>
<ul>
<li>Experimental philosophers should be understood to be presenting second-order evidence in support of the proposition that intuitions have first-order evidential status.</li>
<li>There is room for skepticism, experts might have valid intuitions while other intuitions are devoid of evidential value.</li>
</ul>
<!-- ### A Framework for Studying Classification Judgments and Error Possibilities -->

<h3 id="problems-for-evidential-status-under-free-floating-classifiers">Problems for Evidential Status under Free-Floating Classifiers</h3>
<ul>
<li>The next class of classifiers I shall consider for philosophical analysis are FFC,
<ul>
<li>Under any approach to the proper type of classifier, respondents engaged in classification will need to execute two prior tasks to be successful:
<ol style="list-style-type: decimal">
<li>Acquire a proper understanding of the case,</li>
<li>Acquire a proper understanding of the classification.</li>
</ol></li>
<li>To defend intuitional methodology, these must be possible.
<ul>
<li>The classifications?
<ol style="list-style-type: decimal">
<li>Knowledge</li>
<li>Causation</li>
<li>Object composition</li>
<li>Personal identity<sup><a href="#fn10" class="footnoteRef" id="fnref10">10</a></sup></li>
</ol></li>
</ul></li>
</ul></li>
<li>If we have the requisite concepts to intuitively make judgements about the anlsysis of philosophical objects, why should we engage in point-counterpoint with intuitional methodology, we should just <em>consult the faculties</em> we have.</li>
</ul>
<h3 id="community-specific-classifiers">Community-Specific Classifiers</h3>
<ul>
<li>Given the bleak outlook of FFC, we should turn to &quot;community-specific classifiers.&quot;</li>
</ul>
<!-- ### Processes of Classification Judgement: Preparatory and Final -->

<!-- ### A Dispositional Conception of Classificational Competence -->

<h3 id="a-social-epistemological-perspective-on-intuitional-evidence">A Social-Epistemological Perspective on Intuitional Evidence</h3>
<blockquote>
<p><strong>(Basic evidence-possession)</strong> If S is in a conscious mental state at t that is an evidential state, then S possesses that evidence at t.</p>
<p><strong>(Non-basic evidence-possession)</strong> If proposition p is true and S justifiably believes p at t, then S possesses p as an item of evidence at t.</p>
</blockquote>
<!-- ### Intuitional Methodology and the A Priori -->

<h2 id="november-18th-2013-seminar">November 18th, 2013 <small>Seminar</small></h2>
<dl>
<dt>Occurrent</dt>
<dd><p>Present mental states</p>
</dd>
<dt>Dispositional</dt>
<dd><p>Stored mental states</p>
</dd>
<dt>Intution</dt>
<dd><p>Occurrent mental states, either intuitive judgments or non-doxastic intellectual &quot;seemings&quot; or &quot;attractions.&quot; Spontaneous, non-inferential.</p>
</dd>
</dl>
<ul>
<li>Mostly what we philosophically theorize about in the core branches of philosophy, like epistemology, metaphysics, ethics, ..., these are topics about which ordinary people think and deal and have some competence.</li>
</ul>
<p>This is where empiricism and rationalism are injected into the the philosophical method debate, where the role of philosophers is to tease out relevant features for a concept and then &quot;putting it to the vote&quot; to the folk, and systematizing those intuition. Because the folk cannot theorize and the philosophers cannot intuit.</p>
<ul>
<li>There is a right answer, it is necessarily true</li>
<li>We can get it from the armchair, before looking for evidence
<ul>
<li>The theory is hard and not easily accessible</li>
</ul></li>
<li>The answer is easily accessible to folk without theory</li>
<li>Theorist cannot intuit and folk cannot theorize</li>
<li>We have to go to the armchair for the necessarily true candidate theories</li>
<li>We have to go to the laboratory to get the intuitions to refute candidates</li>
</ul>
<blockquote>
<p>What is the philosopher trying to do?</p>
</blockquote>
<ul>
<li>General meaning or concept of knowledge.
<ul>
<li>There is some correct answer.
<ul>
<li>We used to think JTB.</li>
</ul></li>
<li>Knowledge is a relation between a person and a proposition.
<ul>
<li>When does it hold?</li>
</ul></li>
</ul></li>
</ul>
<table>
<thead>
<tr class="header">
<th align="left">Classifiers</th>
<th align="left">Epistemologically Possible?</th>
<th align="left">Philosophical Desirability</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td align="left">PSC</td>
<td align="left">+</td>
<td align="left">-</td>
</tr>
<tr class="even">
<td align="left">CSC</td>
<td align="left">+</td>
<td align="left">-</td>
</tr>
<tr class="odd">
<td align="left">FFC</td>
<td align="left">-</td>
<td align="left">+</td>
</tr>
</tbody>
</table>
<h2 id="november-25th-2013-chapter-11-social-epistemology-collective-epistemology">November 25th, 2013 <small>Chapter 11, 'Social Epistemology (Collective Epistemology)'</small></h2>
<h3 id="some-terminology">Some Terminology</h3>
<dl>
<dt>Disagree</dt>
<dd><p><span class="math">\(S_1\)</span> and <span class="math">\(S_2\)</span> <em>disagree</em> about <span class="math">\(p\)</span> just in case one believe <span class="math">\(p\)</span> and the other believes <span class="math">\(\lnot p\)</span><sup><a href="#fn11" class="footnoteRef" id="fnref11">11</a></sup></p>
</dd>
<dt>Reasonably disagree</dt>
<dd><p><span class="math">\(S_1\)</span> and <span class="math">\(S_2\)</span> <em>reasonably disagree</em> about <span class="math">\(p\)</span> just in case <span class="math">\(S_1\)</span> and <span class="math">\(S_2\)</span> disagree about <span class="math">\(p\)</span> and both are reasonable (or justified) in their respective beliefs about <span class="math">\(p\)</span>.</p>
</dd>
<dt>Epistemic peers</dt>
<dd><p><span class="math">\(S_1\)</span> and <span class="math">\(S_2\)</span> are epistemic peers (with respect to a domain <span class="math">\(D\)</span>) just in case <span class="math">\(S_1\)</span> and <span class="math">\(S_2\)</span> are equally rational, knowledgeable, intelligent, and evidentially informed about matters pertaining to <span class="math">\(D\)</span>.</p>
</dd>
<dt>Epistemic inferiority and superiority</dt>
<dd><p><span class="math">\(S_1\)</span> is <span class="math">\(S_2\)</span>'s <em>epistemic inferior</em> and <span class="math">\(S_2\)</span> is <span class="math">\(S_1\)</span>'s <em>epistemic superior</em> with respect to a domain just in case <span class="math">\(S_2\)</span> is more rational more intelligent, and more evidentially informed about matters pertaining to <span class="math">\(D\)</span> than <span class="math">\(S_1\)</span>.</p>
</dd>
<dt>Peerhood</dt>
<dd><p>If you have the general idea of what peer hood, it is not being &gt; explained well by the usual definitions. For instance, consider &gt; the actual peers that do not believe they are peers. &gt; Alternatively, that the peers believe they are peers but are not &gt; justified in believing that (and it's false).</p>
</dd>
<dd><p>Feldman (2007): intelligence; reasoning powers; background information, etc.</p>
</dd>
<dd><p>Goldman (2012): Feldman’s (above) criteria; both parties exchange evidence and discuss the matter; neither party withholds information from the other</p>
</dd>
<dd><p>Kelly (2010): parties should assess relevant evidence equally well; they should have comparable track records in making reliable judgments in the relevant domain.</p>
</dd>
</dl>
<div class="figure">
<img src="../img/pic_se_pd.png" alt="Goldman&#39;s picture of Peer Disagreement" /><p class="caption">Goldman's picture of Peer Disagreement</p>
</div>
<h3 id="the-problem">The Problem</h3>
<ul>
<li>What does rationality require or permit when known epistemic peers disagree about <span class="math">\(p\)</span>? What does it require or permit when:
<ol style="list-style-type: decimal">
<li>You and I are epistemic peers with regard to a domain;</li>
<li>We are both aware of (1);</li>
<li>You believe <span class="math">\(p\)</span> and I hold the opposite;</li>
<li>We are both away of (3);</li>
<li>We have compared notes and evaluated all relevant evidence with respect to the matter<sup><a href="#fn12" class="footnoteRef" id="fnref12">12</a></sup>.</li>
</ol></li>
</ul>
<blockquote>
<p><strong>(Liar Politician)</strong>: A politician may have lied. You're convinced he he did; I'm convinced he didn't. We have read the exact same evidence, and know as much. Moreover, we acknowledge each other's epistemic peer-hood relation with respect to the issue. Still, we disagree over the matter.</p>
</blockquote>
<dl>
<dt>Conciliationism</dt>
<dd><p>The rational response in the above case is to suspend judgement/retreat to agnosticism about the case<sup><a href="#fn13" class="footnoteRef" id="fnref13">13</a></sup>.</p>
</dd>
<dt>Equal Weight View</dt>
<dd><p>In cases of peer disagreement, one should give equal weight to the opinion of a peer and to one's own opinion.</p>
</dd>
<dt>Steadfastness<sup><a href="#fn14" class="footnoteRef" id="fnref14">14</a></sup></dt>
<dd><p>The rational response in the above case is to retain one's initial belief.</p>
</dd>
</dl>
<h3 id="conciliationism-steadfastness-and-uniqueness">Conciliationism, Steadfastness, and Uniqueness</h3>
<ul>
<li>An argument for Conciliationism:
<ol style="list-style-type: decimal">
<li>Epistemic peers disagree about <span class="math">\(p\)</span> at <span class="math">\(t\)</span>.</li>
<li>UT: For any proposition and body of evidence, exactly one attitude is reasonable to take towards the proposition.</li>
<li>If UT and (1), at least one person is in violation of the reasonable attitude towards <span class="math">\(p\)</span>.</li>
<li>So our initial attitudes can't both be reasonable.</li>
<li>Insofar as we acknowledge each other as peers, neither of us can rationally conclude that the other is violation of the epistemic principle concerning <span class="math">\(p\)</span>.</li>
<li>So, we should both suspend judgement.</li>
</ol></li>
</ul>
<blockquote>
<p><strong>The Total Evidence View</strong>: “... what it is reasonable to believe depends on both the original, first-order evidence as well as on the higher-order evidence that is afforded by the fact that one’s peers believe as they do” (p. 33).</p>
</blockquote>
<ul>
<li>Conciliationism is self-undermining
<ul>
<li>Disagreement about disagreement: conciliationism would “call for its own rejection”</li>
<li>This is incoherent: conciliation would seem to recommend taking an action that would suggest that it is false.</li>
</ul></li>
</ul>
<h2 id="december-2nd-2013-seminar">December 2nd, 2013 <small>Seminar</small></h2>
<h3 id="terminology">Terminology</h3>
<dl>
<dt>Belief aggregation function</dt>
<dd>At least for a certain range of groups it is natural to think that a group’s doxastic attitude toward a given proposition is grounded in (or supervenes on) the doxastic attitudes of its members. We can represent such a grounding or supervenience relation in terms of a function, or mapping, from beliefs of the members into a belief of the group.
</dd>
</dl>
<h2 id="december-9th-2013-presentation-on-strevens-the-priority-rule-and-herding">December 9th, 2013 <small>Presentation on Strevens, the Priority Rule, and Herding</small></h2>
<p>According to Strevens (2003), whether two scientists make the same discovery – but one makes the discovery ten days before the other – that scientist should be conferred all the benefits and credit for making the discovery. This much seems right. Rewards for scientific discoveries are much like winner-take-all races with any place but first receiving no reward (or credit).</p>
<p>What is <strong>credit</strong>? “It is the standing that a researcher accrues in virtue of their past contributions to knowledge and know-how – their standing, in the first instance, in the scientific community rather than the world at large. <strong>Credit is, then, what other writers have called reputation, credibility, prestige, status, fame.</strong>”</p>
<p>Strevens seeks to answer the following question, “Why does the scientific community disburse prestige in accordance with the priority rule rather than one of the above reward schemes, or some alternative scheme?”</p>
<p>Here are the alternative schemes he has in mind.</p>
<p>Alternatives to the priority rule:</p>
<ol style="list-style-type: decimal">
<li>Scientists might all, on an egalitarian reward system, receive equal compensation – that is, for the purposes of this paper, equal prestige.</li>
<li>Scientists might be compensated in proportion to the talent and effort they invest in their research. Harder working, cleverer scientists would receive more prestige.</li>
<li>Scientists might be compensated in proportion to their actual achievements, in accordance with the priority rule, but with the amendment that being the second to make a discovery, or having progressed considerably towards making a discovery, count as actual achievements. Runners-up in a scientific race would, in other words, receive for finishing as well.</li>
</ol>
<h3 id="section">1</h3>
<p>Why we shouldn’t accept (1):</p>
<p>It seems like an odd, improper allocation of resources to compensate everyone who makes a discovery regardless of the time. For instance, if a scientist makes a discovery and then a group of scientists make that same discovery much later – i.e. a year later – it seems like they should not receive the same resources or credit the first scientist got.</p>
<p>Why we shouldn’t accept (2): We can have hard working, clever scientists who again make the discovery much later. We could reward scientists who pursue ultimately “unworthwhile” projects. This looks like a bad allocation of resources.</p>
<p>But I wonder how this analysis accounts for independent discoveries that seem to be useful. Why not accept the third option?</p>
<p>Consider the following cases.</p>
<blockquote>
<p><strong>Leibniz-Newton controversy</strong>: Most people credit Newton with the discovery of calculus. Most people also agree that Leibniz and Newton independently discovered calculus, but we use Leibniz’s notation because it is easier to use. It seems like both contributed in some way to the development of calculus. Even if Newton is credited with the creation of calculus, it seems like Leibniz offered some sort of novel contribution worth some credit.</p>
</blockquote>
<blockquote>
<p><strong>Raphson-Newton method</strong>: Raphson published findings 50 years prior to Newton on how to best approximate the roots of an equation. Newton came up with similar methods. Raphson’s way of doing the mathematics was simpler and, like Leibniz, made use of easier notation. But it seems like Newton should also be credited here. Why? Because Newton and Raphson shared papers together. Newton’s Method of Fluxions was written in 1671 but it was not published until 1736. Raphson’s Analysis Aequationum Universalis was published in 1690.</p>
</blockquote>
<p>Question: Why not think that the runner-up, in this case Leibniz, contributed an actual achievement?</p>
<p>Possible response:</p>
<blockquote>
<p>Leibniz can be credited for coming up with a particular procedure, e.g. the notation, but not calculus. In other words, Leibniz did not provide an actual achievement.</p>
</blockquote>
<h3 id="section-1">2</h3>
<p>Ways the priority rule might go wrong:</p>
<ol style="list-style-type: decimal">
<li>Scientists might deliberately abandon the priority rule—if, for example, it were perceived to be unfair and in need of reform.</li>
<li>Scientists might for some reason lose their taste for credit, for status, for reputation – hard though that might be to imagine.</li>
<li>Other incentives might swamp or otherwise distort the motivating force of credit. Then, although single-mindedly credit-seeking scientists would distribute themselves optimally, fully human scientists might not – if, for example, they received enormous grants from politically or economically motivated actors to join a particular research program regardless of its meager prospects.</li>
</ol>
<p>Scientists might badly overestimate or underestimate their expected contribution to a research program.</p>
<p>The latter two seem like the biggest areas for concern.</p>
<h3 id="section-2">3</h3>
<p>Herding: When a single research program ends up with a number of researchers well in excess of the “optimum.”</p>
<p>If we take the priority rule as a way to work towards an optimal distribution of scientists for diverse research programs, then everything is fine. But how does this work?</p>
<p>If funding bodies only offer resources for the expected contribution of a particular program, how could we avoid many scientists pursuing only the program with only the highest expected contribution? Then we might end up with many research programs that have perhaps higher risks (i.e. they threaten a scientists’ professional career if pursued because there might be little to no payoff versus the time invested) and are not explored at all.</p>
<p>Take two research programs with equal potential. One is predictive; the other is explanatory (this doesn’t mean that one’s predictions are any better than the other).</p>
<p>Predictive programs: Think of work in quantum mechanics, or general relativity, or special relativity.</p>
<p>Explanatory programs: Think of evolutionary theories which, in some cases, seek to mathematically reproduce the direction or trend of evolution relatively precisely. But there is little predictive power.</p>
<p>If there is a bias towards predictive rather than more explanatory theories, then scientists might want to join the former but not the latter. Scientists won’t shun explanatory programs but they would join them in smaller numbers by comparison. We start to have so many scientists in the predictive program that it begins to have marginal returns. So the expected contribution of any scientist who joins from that point on decreases. Now the predictive program becomes less attractive. But if the explanatory program is becoming less attractive at just a slightly quicker pace than the predictive program, we have the aforementioned herding effect.</p>
<p>How do we avoid this so we can promote diversity of programs in the sciences?</p>
<p>Possible answer: Have funding bodies that offer incentivesthat provide motivation to join small, explanatory research program. (There would still be a worry for scientists who do join that program: their work would not receive the applause of their own scientific community – economics, psychology, etc.)</p>
<!-- Acronyms -->

<!-- Footnotes -->

<div class="footnotes">
<hr />
<ol>
<li id="fn1"><p>Ernest Sosa (2003) raises this problem as a problem for both dogmatists and indirectness theories.<a href="#fnref1">↩</a></p></li>
<li id="fn2"><p>Michael Huemer's &quot;phenomenal conservatism.&quot;<a href="#fnref2">↩</a></p></li>
<li id="fn3"><p>I very much doubt this, or at least have reason to doubt this. Imagine that someone has face-blindness, is aware of their face-blindness, and the experience of seeing a specific person.<a href="#fnref3">↩</a></p></li>
<li id="fn4"><p>No one would disagree here, the conditional is valid. But the question is <em>are intuitions reliable indicators</em> and <em>which intuitions are reliable indicators of what</em>?<a href="#fnref4">↩</a></p></li>
<li id="fn5"><p>Does that mean that when experimental philosophy's intuition findings do not correspond to philosophical tradition we should throw out experimental philosophy's methodology or traditional philosophy's thought? I think the former.<a href="#fnref5">↩</a></p></li>
<li id="fn6"><p>We can construct a Sorites paradox from this.<a href="#fnref6">↩</a></p></li>
<li id="fn7"><p>By three or four, you can give verbal tests and work out that the babies can read minds, even children as 14 months have some sort of mind reading, obviously not verbal tests. How long an infant fixates on a certain individual, if you're surprised, that can be an indicator. Mind-reading is believing that so or so is a mental state.<a href="#fnref7">↩</a></p></li>
<li id="fn8"><p>Heuristics fits nicely with process reliability, and I think that in at least some way, our heuristics must be useful in abstracting something at sometime, for instance if we're be hunted by some other animal, it is not useful to question whether our perception is good, but we can engage in this question in moments of safety and luxury, but what we may be programmed might no longer fit.<a href="#fnref8">↩</a></p></li>
<li id="fn9"><p>And here we have a regress problem! Oh no!<a href="#fnref9">↩</a></p></li>
<li id="fn10"><p>These change with culture because they are normative! Oh no!<a href="#fnref10">↩</a></p></li>
<li id="fn11"><p>Note: Disagreement requires that S1 and S2 hold two positive, yet incompatible, doxastic attitudes toward p. To affirm that p is to positively believe that p is true (and thereby to believe that its negation is false). To deny that p is to positively believe that ¬ p is true (and thereby to believe that its negation is false).<a href="#fnref11">↩</a></p></li>
<li id="fn12"><p>What about when the domain is the criteria for peer hood, the proposition is &quot;<span class="math">\(S_1\)</span> and <span class="math">\(S_2\)</span> are peers.&quot; and <span class="math">\(S_1\)</span> and <span class="math">\(S_2\)</span> assent and dissent respectively.<a href="#fnref12">↩</a></p></li>
<li id="fn13"><p>There are two sense of suspension. There is the &quot;time out&quot; sense of suspension, &quot;Hold on! Let me think about this.&quot; And then there chess. There is a difference between &quot;no view&quot; and &quot;middle view.&quot;<a href="#fnref13">↩</a></p></li>
<li id="fn14"><p>What I think this is answering is &quot;When is a peer's disagreeing with me evidence sufficient to change my attitude?&quot;<a href="#fnref14">↩</a></p></li>
</ol>
</div> 
{% endraw %}